{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovering Reddit Sentiment Stock Trends\n",
    "\n",
    "Methods used includes Logistic Regression, Naive Bayes Gaussian, Naive Bayes Categorical, and Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed importing tools\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\trane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\trane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\trane\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sentiment Analysis\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# EDA\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from collections import Counter\n",
    "\n",
    "# Module with the deprecation in python version 3.7 and above\n",
    "# However, works fine for me in python version 3.9.1\n",
    "# Commented it out just to be safe\n",
    "#%pip install wordcloud\n",
    "#from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Cleaning up the text\n",
    "import re\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Splitting for test and train sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Neural Network\n",
    "from keras.utils import np_utils\n",
    "\n",
    "print(\"Completed importing tools\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Reddit Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's not about the money, it's about sending a...</td>\n",
       "      <td>55</td>\n",
       "      <td>l6ulcx</td>\n",
       "      <td>https://v.redd.it/6j75regs72e61</td>\n",
       "      <td>6</td>\n",
       "      <td>1.611863e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:37:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Math Professor Scott Steiner says the numbers ...</td>\n",
       "      <td>110</td>\n",
       "      <td>l6uibd</td>\n",
       "      <td>https://v.redd.it/ah50lyny62e61</td>\n",
       "      <td>23</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:32:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exit the system</td>\n",
       "      <td>0</td>\n",
       "      <td>l6uhhn</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>The CEO of NASDAQ pushed to halt trading “to g...</td>\n",
       "      <td>2021-01-28 21:30:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n",
       "      <td>29</td>\n",
       "      <td>l6ugk6</td>\n",
       "      <td>https://sec.report/Document/0001193125-21-019848/</td>\n",
       "      <td>74</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:28:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not to distract from GME, just thought our AMC...</td>\n",
       "      <td>71</td>\n",
       "      <td>l6ufgy</td>\n",
       "      <td>https://i.redd.it/4h2sukb662e61.jpg</td>\n",
       "      <td>156</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:26:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score      id  \\\n",
       "0  It's not about the money, it's about sending a...     55  l6ulcx   \n",
       "1  Math Professor Scott Steiner says the numbers ...    110  l6uibd   \n",
       "2                                    Exit the system      0  l6uhhn   \n",
       "3  NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...     29  l6ugk6   \n",
       "4  Not to distract from GME, just thought our AMC...     71  l6ufgy   \n",
       "\n",
       "                                                 url  comms_num       created  \\\n",
       "0                    https://v.redd.it/6j75regs72e61          6  1.611863e+09   \n",
       "1                    https://v.redd.it/ah50lyny62e61         23  1.611862e+09   \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...         47  1.611862e+09   \n",
       "3  https://sec.report/Document/0001193125-21-019848/         74  1.611862e+09   \n",
       "4                https://i.redd.it/4h2sukb662e61.jpg        156  1.611862e+09   \n",
       "\n",
       "                                                body            timestamp  \n",
       "0                                                NaN  2021-01-28 21:37:41  \n",
       "1                                                NaN  2021-01-28 21:32:10  \n",
       "2  The CEO of NASDAQ pushed to halt trading “to g...  2021-01-28 21:30:35  \n",
       "3                                                NaN  2021-01-28 21:28:57  \n",
       "4                                                NaN  2021-01-28 21:26:56  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import reddit dataset\n",
    "og_reddit = pd.read_csv('reddit_wsb.csv')\n",
    "og_reddit.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Reddit Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's not about the money, it's about sending a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Math Professor Scott Steiner says the numbers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exit the system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not to distract from GME, just thought our AMC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0  It's not about the money, it's about sending a...\n",
       "1  Math Professor Scott Steiner says the numbers ...\n",
       "2                                    Exit the system\n",
       "3  NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...\n",
       "4  Not to distract from GME, just thought our AMC..."
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removed columns that I felt unnecessary\n",
    "bad_reddit = ['score', 'id', 'url',\n",
    "              'comms_num', 'created', 'body', 'timestamp']\n",
    "clean_reddit = og_reddit.drop(bad_reddit, axis=1)\n",
    "clean_reddit.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Reddit Titles: 53187\n"
     ]
    }
   ],
   "source": [
    "# Number of cases\n",
    "print('Number of Reddit Titles:', len(clean_reddit['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Referenced: https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "\n",
    "# Functions to cleanup the text\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', str(text))\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", re.UNICODE)\n",
    "    text = re.sub(emoji_pattern, '', text)  # no emoji\n",
    "    return text\n",
    "\n",
    "\n",
    "# Function that applies cleaning to df\n",
    "def clean_text_up(df):\n",
    "    for i in range(df.shape[0]):\n",
    "        df.iat[i, 0] = clean_text(df.iat[i, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>its not about the money its about sending a me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>math professor scott steiner says the numbers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exit the system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new sec filing for gme can someone less retard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not to distract from gme just thought our amc ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0  its not about the money its about sending a me...\n",
       "1  math professor scott steiner says the numbers ...\n",
       "2                                    exit the system\n",
       "3  new sec filing for gme can someone less retard...\n",
       "4  not to distract from gme just thought our amc ..."
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the text\n",
    "clean_text_up(clean_reddit)\n",
    "clean_reddit.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess NYSE Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>19-Nov-2021</td>\n",
       "      <td>163.01</td>\n",
       "      <td>165.0700</td>\n",
       "      <td>162.67</td>\n",
       "      <td>164.3000</td>\n",
       "      <td>1647600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "      <td>19-Nov-2021</td>\n",
       "      <td>47.31</td>\n",
       "      <td>48.0800</td>\n",
       "      <td>46.69</td>\n",
       "      <td>47.6000</td>\n",
       "      <td>5644100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAC</td>\n",
       "      <td>19-Nov-2021</td>\n",
       "      <td>9.84</td>\n",
       "      <td>9.8400</td>\n",
       "      <td>9.79</td>\n",
       "      <td>9.8200</td>\n",
       "      <td>993400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAC.U</td>\n",
       "      <td>19-Nov-2021</td>\n",
       "      <td>10.08</td>\n",
       "      <td>10.0800</td>\n",
       "      <td>10.03</td>\n",
       "      <td>10.0600</td>\n",
       "      <td>12300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAC.W</td>\n",
       "      <td>19-Nov-2021</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.2999</td>\n",
       "      <td>18300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>19-Nov-2021</td>\n",
       "      <td>226.50</td>\n",
       "      <td>228.3300</td>\n",
       "      <td>224.20</td>\n",
       "      <td>226.4300</td>\n",
       "      <td>1734700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>ZUO</td>\n",
       "      <td>19-Nov-2021</td>\n",
       "      <td>22.52</td>\n",
       "      <td>22.7100</td>\n",
       "      <td>22.00</td>\n",
       "      <td>22.0900</td>\n",
       "      <td>596400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>ZVIA</td>\n",
       "      <td>19-Nov-2021</td>\n",
       "      <td>8.24</td>\n",
       "      <td>8.2835</td>\n",
       "      <td>7.72</td>\n",
       "      <td>7.9300</td>\n",
       "      <td>405500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>ZWS</td>\n",
       "      <td>19-Nov-2021</td>\n",
       "      <td>37.90</td>\n",
       "      <td>38.3150</td>\n",
       "      <td>37.69</td>\n",
       "      <td>37.9000</td>\n",
       "      <td>665300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>ZYME</td>\n",
       "      <td>19-Nov-2021</td>\n",
       "      <td>19.48</td>\n",
       "      <td>20.0400</td>\n",
       "      <td>19.26</td>\n",
       "      <td>19.8100</td>\n",
       "      <td>943100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3497 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Symbol         Date    Open      High     Low     Close   Volume\n",
       "0         A  19-Nov-2021  163.01  165.0700  162.67  164.3000  1647600\n",
       "1        AA  19-Nov-2021   47.31   48.0800   46.69   47.6000  5644100\n",
       "2       AAC  19-Nov-2021    9.84    9.8400    9.79    9.8200   993400\n",
       "3     AAC.U  19-Nov-2021   10.08   10.0800   10.03   10.0600    12300\n",
       "4     AAC.W  19-Nov-2021    1.24    1.3000    1.24    1.2999    18300\n",
       "...     ...          ...     ...       ...     ...       ...      ...\n",
       "3492    ZTS  19-Nov-2021  226.50  228.3300  224.20  226.4300  1734700\n",
       "3493    ZUO  19-Nov-2021   22.52   22.7100   22.00   22.0900   596400\n",
       "3494   ZVIA  19-Nov-2021    8.24    8.2835    7.72    7.9300   405500\n",
       "3495    ZWS  19-Nov-2021   37.90   38.3150   37.69   37.9000   665300\n",
       "3496   ZYME  19-Nov-2021   19.48   20.0400   19.26   19.8100   943100\n",
       "\n",
       "[3497 rows x 7 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import NYSE dataset\n",
    "og_NYSE = pd.read_csv('NYSE_20211119.csv')\n",
    "og_NYSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAC.U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAC.W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol\n",
       "0      A\n",
       "1     AA\n",
       "2    AAC\n",
       "3  AAC.U\n",
       "4  AAC.W"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removed columns that I felt unnecessary\n",
    "bad_NYSE = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
    "clean_NYSE = og_NYSE.drop(bad_NYSE, axis=1)\n",
    "clean_NYSE.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aacu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aacw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol\n",
       "0      a\n",
       "1     aa\n",
       "2    aac\n",
       "3   aacu\n",
       "4   aacw"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the text\n",
    "# Must apply since I did for reddit dataset\n",
    "clean_text_up(clean_NYSE)\n",
    "clean_NYSE.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Sentiment Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.272</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.2748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.2235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos  compound\n",
       "0  0.000  1.000  0.000    0.0000\n",
       "1  0.272  0.728  0.000   -0.6249\n",
       "2  0.000  1.000  0.000    0.0000\n",
       "3  0.204  0.658  0.138   -0.2748\n",
       "4  0.000  0.881  0.119    0.2235"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find sentiment scores\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "scores = []\n",
    "for item in clean_reddit['title']:\n",
    "    score = analyser.polarity_scores(item)\n",
    "    scores.append(score)\n",
    "\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>its not about the money its about sending a me...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>math professor scott steiner says the numbers ...</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exit the system</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new sec filing for gme can someone less retard...</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.2748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not to distract from gme just thought our amc ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.2235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title    neg    neu    pos  \\\n",
       "0  its not about the money its about sending a me...  0.000  1.000  0.000   \n",
       "1  math professor scott steiner says the numbers ...  0.272  0.728  0.000   \n",
       "2                                    exit the system  0.000  1.000  0.000   \n",
       "3  new sec filing for gme can someone less retard...  0.204  0.658  0.138   \n",
       "4  not to distract from gme just thought our amc ...  0.000  0.881  0.119   \n",
       "\n",
       "   compound  \n",
       "0    0.0000  \n",
       "1   -0.6249  \n",
       "2    0.0000  \n",
       "3   -0.2748  \n",
       "4    0.2235  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine clean_reddit and scores_df dataframes\n",
    "combine_df = pd.concat([clean_reddit, scores_df], axis=1, join='inner')\n",
    "combine_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>its not about the money its about sending a me...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>math professor scott steiner says the numbers ...</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6249</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exit the system</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new sec filing for gme can someone less retard...</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.138</td>\n",
       "      <td>-0.2748</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not to distract from gme just thought our amc ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title    neg    neu    pos  \\\n",
       "0  its not about the money its about sending a me...  0.000  1.000  0.000   \n",
       "1  math professor scott steiner says the numbers ...  0.272  0.728  0.000   \n",
       "2                                    exit the system  0.000  1.000  0.000   \n",
       "3  new sec filing for gme can someone less retard...  0.204  0.658  0.138   \n",
       "4  not to distract from gme just thought our amc ...  0.000  0.881  0.119   \n",
       "\n",
       "   compound class  \n",
       "0    0.0000   neu  \n",
       "1   -0.6249   neu  \n",
       "2    0.0000   neu  \n",
       "3   -0.2748   neu  \n",
       "4    0.2235   neu  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the class of each title based off greatest value between neg, neu, pos columns\n",
    "combine_df['class'] = combine_df[['neg', 'neu', 'pos']].idxmax(axis=1)\n",
    "combine_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love you retards</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the wallstreetbets war museum</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>most recent short interest</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i love the movies part</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title    neg    neu    pos  compound class\n",
       "0             i love you retards  0.000  0.417  0.583    0.6369   pos\n",
       "1                                 0.000  0.000  0.000    0.0000   neg\n",
       "2  the wallstreetbets war museum  0.565  0.435  0.000   -0.5994   neg\n",
       "3     most recent short interest  0.000  0.479  0.521    0.5046   pos\n",
       "4        i love the movies part   0.000  0.488  0.512    0.6369   pos"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all neutral classes\n",
    "# Neutral classes will have insignificant value\n",
    "combine_df = combine_df[combine_df['class'] != 'neu']\n",
    "combine_df.reset_index(drop=True, inplace=True)\n",
    "combine_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love you retards</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the wallstreetbets war museum</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>most recent short interest</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i love the movies part</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i see dead hedge funds</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title    neg    neu    pos  compound class\n",
       "0             i love you retards  0.000  0.417  0.583    0.6369   pos\n",
       "1  the wallstreetbets war museum  0.565  0.435  0.000   -0.5994   neg\n",
       "2     most recent short interest  0.000  0.479  0.521    0.5046   pos\n",
       "3        i love the movies part   0.000  0.488  0.512    0.6369   pos\n",
       "4         i see dead hedge funds  0.518  0.482  0.000   -0.6486   neg"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all 0 compound\n",
    "# Compound value of 0 will have insignificant value\n",
    "combine_df = combine_df[combine_df['compound'] != 0]\n",
    "combine_df.reset_index(drop=True, inplace=True)\n",
    "combine_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[i, love, you, retards]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[the, wallstreetbets, war, museum]</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[most, recent, short, interest]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[i, love, the, movies, part]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[i, see, dead, hedge, funds]</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title    neg    neu    pos  compound class\n",
       "0             [i, love, you, retards]  0.000  0.417  0.583    0.6369   pos\n",
       "1  [the, wallstreetbets, war, museum]  0.565  0.435  0.000   -0.5994   neg\n",
       "2     [most, recent, short, interest]  0.000  0.479  0.521    0.5046   pos\n",
       "3        [i, love, the, movies, part]  0.000  0.488  0.512    0.6369   pos\n",
       "4        [i, see, dead, hedge, funds]  0.518  0.482  0.000   -0.6486   neg"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize text\n",
    "combine_df['title'] = combine_df['title'].apply(word_tokenize)\n",
    "combine_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[love, retards]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[wallstreetbets, war, museum]</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[recent, short, interest]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[love, movies, part]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[see, dead, hedge, funds]</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title    neg    neu    pos  compound class\n",
       "0                [love, retards]  0.000  0.417  0.583    0.6369   pos\n",
       "1  [wallstreetbets, war, museum]  0.565  0.435  0.000   -0.5994   neg\n",
       "2      [recent, short, interest]  0.000  0.479  0.521    0.5046   pos\n",
       "3           [love, movies, part]  0.000  0.488  0.512    0.6369   pos\n",
       "4      [see, dead, hedge, funds]  0.518  0.482  0.000   -0.6486   neg"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stopwords\n",
    "# Removing some stopwords will result in removing some stock tickers\n",
    "# For ex. SEE, YOU, etc\n",
    "def remove_stopwords(input):\n",
    "    words = []\n",
    "    for word in input:\n",
    "        if word not in stopwords.words('english'):\n",
    "            words.append(word)\n",
    "    return words\n",
    "\n",
    "\n",
    "combine_df['title'] = combine_df['title'].apply(remove_stopwords)\n",
    "combine_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[love, retard]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[wallstreetbets, war, museum]</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[recent, short, interest]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[love, movie, part]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[see, dead, hedge, fund]</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title    neg    neu    pos  compound class\n",
       "0                 [love, retard]  0.000  0.417  0.583    0.6369   pos\n",
       "1  [wallstreetbets, war, museum]  0.565  0.435  0.000   -0.5994   neg\n",
       "2      [recent, short, interest]  0.000  0.479  0.521    0.5046   pos\n",
       "3            [love, movie, part]  0.000  0.488  0.512    0.6369   pos\n",
       "4       [see, dead, hedge, fund]  0.518  0.482  0.000   -0.6486   neg"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform lemma\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def lemma_wordnet(input):\n",
    "    return [lem.lemmatize(w) for w in input]\n",
    "\n",
    "\n",
    "combine_df['title'] = combine_df['title'].apply(lemma_wordnet)\n",
    "combine_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>class</th>\n",
       "      <th>TrueFalse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[love, retard]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>pos</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[wallstreetbets, war, museum]</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>neg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[recent, short, interest]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>pos</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[love, movie, part]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>pos</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[see, dead, hedge, fund]</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title    neg    neu    pos  compound class  \\\n",
       "0                 [love, retard]  0.000  0.417  0.583    0.6369   pos   \n",
       "1  [wallstreetbets, war, museum]  0.565  0.435  0.000   -0.5994   neg   \n",
       "2      [recent, short, interest]  0.000  0.479  0.521    0.5046   pos   \n",
       "3            [love, movie, part]  0.000  0.488  0.512    0.6369   pos   \n",
       "4       [see, dead, hedge, fund]  0.518  0.482  0.000   -0.6486   neg   \n",
       "\n",
       "   TrueFalse  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          1  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output 1 or 0 if stock ticker is found in title\n",
    "searchfor = clean_NYSE['Symbol']\n",
    "combine_df[\"TrueFalse\"] = combine_df['title'].apply(\n",
    "    lambda x: 1 if any(i in x for i in searchfor) else 0)\n",
    "combine_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>class</th>\n",
       "      <th>TrueFalse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[see, dead, hedge, fund]</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>neg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[thank, mod, team, glorious, retard]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.7717</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[thank, mod]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[best, broker, europe]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[wow]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>pos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title    neg    neu    pos  compound class  \\\n",
       "0              [see, dead, hedge, fund]  0.518  0.482  0.000   -0.6486   neg   \n",
       "1  [thank, mod, team, glorious, retard]  0.000  0.427  0.573    0.7717   pos   \n",
       "2                          [thank, mod]  0.000  0.444  0.556    0.3612   pos   \n",
       "3                [best, broker, europe]  0.000  0.417  0.583    0.6369   pos   \n",
       "4                                 [wow]  0.000  0.000  1.000    0.5859   pos   \n",
       "\n",
       "   TrueFalse  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all rows with no stock tickers\n",
    "# It will probably remove non-acronym stocks\n",
    "combine_df = combine_df[combine_df.TrueFalse != 0]\n",
    "combine_df.reset_index(drop=True, inplace=True)\n",
    "combine_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[see, dead, hedge, fund]</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[thank, mod, team, glorious, retard]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.7717</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[thank, mod]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[best, broker, europe]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[wow]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title    neg    neu    pos  compound class\n",
       "0              [see, dead, hedge, fund]  0.518  0.482  0.000   -0.6486   neg\n",
       "1  [thank, mod, team, glorious, retard]  0.000  0.427  0.573    0.7717   pos\n",
       "2                          [thank, mod]  0.000  0.444  0.556    0.3612   pos\n",
       "3                [best, broker, europe]  0.000  0.417  0.583    0.6369   pos\n",
       "4                                 [wow]  0.000  0.000  1.000    0.5859   pos"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove TrueFalse column\n",
    "combine_df = combine_df.drop('TrueFalse', 1)\n",
    "combine_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>see dead hedge fund</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thank mod team glorious retard</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.7717</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thank mod</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best broker europe</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wow</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title    neg    neu    pos  compound class\n",
       "0             see dead hedge fund  0.518  0.482  0.000   -0.6486   neg\n",
       "1  thank mod team glorious retard  0.000  0.427  0.573    0.7717   pos\n",
       "2                       thank mod  0.000  0.444  0.556    0.3612   pos\n",
       "3              best broker europe  0.000  0.417  0.583    0.6369   pos\n",
       "4                             wow  0.000  0.000  1.000    0.5859   pos"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join the text\n",
    "for i in range(combine_df.shape[0]):\n",
    "    combine_df.iat[i, 0] = ' '.join(combine_df.iat[i, 0])\n",
    "combine_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-97-0c9039f2b123>:2: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "<ipython-input-97-0c9039f2b123>:3: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>see dead hedge fund</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thank mod team glorious retard</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.7717</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thank mod</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best broker europe</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wow</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title    neg    neu    pos  compound class\n",
       "0             see dead hedge fund  0.518  0.482  0.000   -0.6486     0\n",
       "1  thank mod team glorious retard  0.000  0.427  0.573    0.7717     1\n",
       "2                       thank mod  0.000  0.444  0.556    0.3612     1\n",
       "3              best broker europe  0.000  0.417  0.583    0.6369     1\n",
       "4                             wow  0.000  0.000  1.000    0.5859     1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace neg and pos to 0s and 1s\n",
    "combine_df['class'][combine_df['class'] == 'neg'] = 0\n",
    "combine_df['class'][combine_df['class'] == 'pos'] = 1\n",
    "combine_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>see dead hedge fund</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thank mod team glorious retard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thank mod</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best broker europe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title class\n",
       "0             see dead hedge fund     0\n",
       "1  thank mod team glorious retard     1\n",
       "2                       thank mod     1\n",
       "3              best broker europe     1\n",
       "4                             wow     1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy\n",
    "final_df = combine_df[['title', 'class']].copy()\n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sentiment: 806\n",
      "Negative Sentiment: 305\n",
      "Total Cases: 1111\n"
     ]
    }
   ],
   "source": [
    "# Print the total cases\n",
    "print('Positive Sentiment:', len(final_df[final_df['class'] == 1]))\n",
    "print('Negative Sentiment:', len(final_df[final_df['class'] == 0]))\n",
    "print('Total Cases:', len(final_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the final results\n",
    "final_df[\"class\"].hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Negative')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Positive and Negative Sentiments\n",
    "# Output will show that good seperation\n",
    "# Accuracy should be fairly high\n",
    "X_axis = combine_df[['pos', 'neg']].values\n",
    "Y_axis = combine_df['class'].values\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "colors = ['red', 'green']\n",
    "ax.scatter(X_axis[:, 0], X_axis[:, 1], c=[colors[int(k)]\n",
    "                                          for k in Y_axis], s=1)\n",
    "plt.xlabel(\"Positive\")\n",
    "plt.ylabel(\"Negative\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Find common words\\n# wordcloud is deprecated in python version 3.7 and above\\n# for some reason, it works fine for me on version 3.9.1\\n# Commented out just to be safe\\nbody_list = final_df.title.tolist()\\nfig_wordcloud = WordCloud(stopwords=STOPWORDS, background_color='lightgrey',\\n                          colormap='viridis', width=800, height=600\\n                          ).generate(' '.join(body_list))\\n\\nplt.figure(figsize=(10, 7), frameon=True)\\nplt.imshow(fig_wordcloud)\\nplt.axis('off')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Find common words\n",
    "# wordcloud is deprecated in python version 3.7 and above\n",
    "# for some reason, it works fine for me on version 3.9.1\n",
    "# Commented out just to be safe\n",
    "body_list = final_df.title.tolist()\n",
    "fig_wordcloud = WordCloud(stopwords=STOPWORDS, background_color='lightgrey',\n",
    "                          colormap='viridis', width=800, height=600\n",
    "                          ).generate(' '.join(body_list))\n",
    "\n",
    "plt.figure(figsize=(10, 7), frameon=True)\n",
    "plt.imshow(fig_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_1750c_row0_col1{\n",
       "            background-color:  #3f007d;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_1750c_row1_col1{\n",
       "            background-color:  #c8c8e2;\n",
       "            color:  #000000;\n",
       "        }#T_1750c_row2_col1{\n",
       "            background-color:  #eae9f3;\n",
       "            color:  #000000;\n",
       "        }#T_1750c_row3_col1{\n",
       "            background-color:  #eeecf5;\n",
       "            color:  #000000;\n",
       "        }#T_1750c_row4_col1{\n",
       "            background-color:  #f3f1f7;\n",
       "            color:  #000000;\n",
       "        }#T_1750c_row5_col1{\n",
       "            background-color:  #f8f7fa;\n",
       "            color:  #000000;\n",
       "        }#T_1750c_row6_col1,#T_1750c_row7_col1{\n",
       "            background-color:  #faf9fc;\n",
       "            color:  #000000;\n",
       "        }#T_1750c_row8_col1{\n",
       "            background-color:  #fcfbfd;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_1750c_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Common_words</th>        <th class=\"col_heading level0 col1\" >count</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_1750c_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "                        <td id=\"T_1750c_row0_col0\" class=\"data row0 col0\" >gme</td>\n",
       "                        <td id=\"T_1750c_row0_col1\" class=\"data row0 col1\" >238</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1750c_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "                        <td id=\"T_1750c_row1_col0\" class=\"data row1 col0\" >amc</td>\n",
       "                        <td id=\"T_1750c_row1_col1\" class=\"data row1 col1\" >111</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1750c_level0_row2\" class=\"row_heading level0 row2\" >3</th>\n",
       "                        <td id=\"T_1750c_row2_col0\" class=\"data row2 col0\" >gain</td>\n",
       "                        <td id=\"T_1750c_row2_col1\" class=\"data row2 col1\" >78</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1750c_level0_row3\" class=\"row_heading level0 row3\" >4</th>\n",
       "                        <td id=\"T_1750c_row3_col0\" class=\"data row3 col0\" >pltr</td>\n",
       "                        <td id=\"T_1750c_row3_col1\" class=\"data row3 col1\" >74</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1750c_level0_row4\" class=\"row_heading level0 row4\" >5</th>\n",
       "                        <td id=\"T_1750c_row4_col0\" class=\"data row4 col0\" >share</td>\n",
       "                        <td id=\"T_1750c_row4_col1\" class=\"data row4 col1\" >66</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1750c_level0_row5\" class=\"row_heading level0 row5\" >6</th>\n",
       "                        <td id=\"T_1750c_row5_col0\" class=\"data row5 col0\" >update</td>\n",
       "                        <td id=\"T_1750c_row5_col1\" class=\"data row5 col1\" >57</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1750c_level0_row6\" class=\"row_heading level0 row6\" >7</th>\n",
       "                        <td id=\"T_1750c_row6_col0\" class=\"data row6 col0\" >best</td>\n",
       "                        <td id=\"T_1750c_row6_col1\" class=\"data row6 col1\" >53</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1750c_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "                        <td id=\"T_1750c_row7_col0\" class=\"data row7 col0\" >well</td>\n",
       "                        <td id=\"T_1750c_row7_col1\" class=\"data row7 col1\" >53</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_1750c_level0_row8\" class=\"row_heading level0 row8\" >9</th>\n",
       "                        <td id=\"T_1750c_row8_col0\" class=\"data row8 col0\" >rkt</td>\n",
       "                        <td id=\"T_1750c_row8_col1\" class=\"data row8 col1\" >49</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x202ef01dd60>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find common words\n",
    "common = pd.DataFrame()\n",
    "common['words'] = final_df['title'].apply(word_tokenize)\n",
    "top = Counter([item for sublist in common['words'] for item in sublist])\n",
    "temp = pd.DataFrame(top.most_common(10))\n",
    "temp = temp.iloc[1:, :]\n",
    "temp.columns = ['Common_words', 'count']\n",
    "temp.style.background_gradient(cmap='Purples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "gme",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "gme",
         "offsetgroup": "gme",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          238
         ],
         "xaxis": "x",
         "y": [
          "gme"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "amc",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "amc",
         "offsetgroup": "amc",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          111
         ],
         "xaxis": "x",
         "y": [
          "amc"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "gain",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "gain",
         "offsetgroup": "gain",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          78
         ],
         "xaxis": "x",
         "y": [
          "gain"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "pltr",
         "marker": {
          "color": "#ab63fa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "pltr",
         "offsetgroup": "pltr",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          74
         ],
         "xaxis": "x",
         "y": [
          "pltr"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "share",
         "marker": {
          "color": "#FFA15A",
          "pattern": {
           "shape": ""
          }
         },
         "name": "share",
         "offsetgroup": "share",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          66
         ],
         "xaxis": "x",
         "y": [
          "share"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "update",
         "marker": {
          "color": "#19d3f3",
          "pattern": {
           "shape": ""
          }
         },
         "name": "update",
         "offsetgroup": "update",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          57
         ],
         "xaxis": "x",
         "y": [
          "update"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "best",
         "marker": {
          "color": "#FF6692",
          "pattern": {
           "shape": ""
          }
         },
         "name": "best",
         "offsetgroup": "best",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          53
         ],
         "xaxis": "x",
         "y": [
          "best"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "well",
         "marker": {
          "color": "#B6E880",
          "pattern": {
           "shape": ""
          }
         },
         "name": "well",
         "offsetgroup": "well",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          53
         ],
         "xaxis": "x",
         "y": [
          "well"
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "Common_words=%{y}<br>count=%{x}<extra></extra>",
         "legendgroup": "rkt",
         "marker": {
          "color": "#FF97FF",
          "pattern": {
           "shape": ""
          }
         },
         "name": "rkt",
         "offsetgroup": "rkt",
         "orientation": "h",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          49
         ],
         "xaxis": "x",
         "y": [
          "rkt"
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "height": 700,
        "legend": {
         "title": {
          "text": "Common_words"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Commmon Words in Text"
        },
        "width": 700,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        },
        "yaxis": {
         "anchor": "x",
         "categoryarray": [
          "rkt",
          "well",
          "best",
          "update",
          "share",
          "pltr",
          "gain",
          "amc",
          "gme"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Common_words"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# common words\n",
    "fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Text', orientation='h',\n",
    "             width=700, height=700, color='Common_words')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Logistics Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: read only \"title\", text\n",
    "# Y: read only \"class\", 0s and 1s\n",
    "X = final_df['title'].values\n",
    "y = final_df['class'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change datatype and reshape\n",
    "y_train = np.asarray(y_train, dtype='int32')\n",
    "y_test = np.asarray(y_test, dtype='int32')\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amc', 'gme', 'pltr', 'natural', 'language', 'processing', 'nlp', 'field']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing stopwords and stemming for better accuracy\n",
    "def clean_stopword_lemma(title):\n",
    "    lem = WordNetLemmatizer()\n",
    "    title = title.lower()\n",
    "    sw_nltk = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(title)\n",
    "\n",
    "    cleaned = [w for w in word_tokens if not w.lower() in sw_nltk]\n",
    "\n",
    "    cleaned = []\n",
    "\n",
    "    for w in word_tokens:\n",
    "        if w not in sw_nltk and w not in string.punctuation:\n",
    "            lemma = lem.lemmatize(w)\n",
    "            cleaned.append(lemma)\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "# Test\n",
    "text = \"AMC GME PLTR Natural language processing (NLP) is a field \"\n",
    "clean_stopword_lemma(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get frequency dictionary\n",
    "# reddit: a list of reddit titles\n",
    "# ys: an m x 1 array with the sentiment label of each title (either 0 or 1)\n",
    "# squeeze(): Remove single-dimensional entries from the shape of an array.\n",
    "#  zip(): function accepts iterable items and merges them into a single tuple.\n",
    "def reddit_freqs(reddit, ys):\n",
    "    # Convert np array to list since zip needs an iterable.\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "    # Count freqs and generate dictionary\n",
    "    freqs = {}\n",
    "    for yt, title in zip(yslist, reddit):\n",
    "        for word in clean_stopword_lemma(title):\n",
    "            # define the key, which is the word and label tuple\n",
    "            pair = (word, yt)\n",
    "            # if the key exists in the dictionary, increment the count\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            # else, if the key is new, add it to the dictionary and set the count to 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "    return freqs\n",
    "\n",
    "\n",
    "freqs = reddit_freqs(X_train, y_train)\n",
    "# Test\n",
    "# print(freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sigmoid\n",
    "def sigmoid(z):\n",
    "    return (1 / (1 + np.exp(-z)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply gradient descent\n",
    "def gradientDescent(x, y, theta, alpha, iter):\n",
    "    # get 'm', the number of rows in matrix x\n",
    "    m = x.shape[0]\n",
    "\n",
    "    for i in range(0, iter):\n",
    "\n",
    "        # get z, the dot product of x and theta\n",
    "        z = np.dot(x, theta)\n",
    "\n",
    "        # get the sigmoid of h\n",
    "        h = sigmoid(z)\n",
    "\n",
    "        # calculate the cost function\n",
    "        J = (-1/m) * (np.dot((y.transpose()), np.log(h)) +\n",
    "                      np.dot((1 - y).transpose(), np.log(1 - h)))\n",
    "\n",
    "        # update the weights theta\n",
    "        theta = theta - (alpha/m) * np.dot(x.T, (h - y))\n",
    "\n",
    "    J = float(J)\n",
    "\n",
    "    return J, theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the features\n",
    "def extract_features(title, freqs):\n",
    "    # clean the titles\n",
    "    word_list = clean_stopword_lemma(title)\n",
    "    # x is a 1 x 3 matrix\n",
    "    x = np.zeros((1, 3))\n",
    "    # bias is set to 1\n",
    "    x[0, 0] = 1\n",
    "    # loop through each word in the list of words\n",
    "    for word in word_list:\n",
    "        # increment the word count for the positive label 1\n",
    "        x[0, 1] += freqs.get((word, 1.0), 0)\n",
    "        # increment the word count for the negative label 0\n",
    "        x[0, 2] += freqs.get((word, 0.0), 0)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.40540780.\n",
      "The resulting weight vector is [0.00437096, 0.03177147, -0.05450412]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "# Stack the features for all training examples into a matrix X.\n",
    "# Call gradientDescent\n",
    "# squeeze: Remove single-dimensional entries from the shape of an array.\n",
    "def train_logistic_regression(freqs, X_train, y_train):\n",
    "    # collect the features x and stack them into a matrix X\n",
    "    X = np.zeros((len(X_train), 3))\n",
    "    for i in range(len(X_train)):\n",
    "        X[i, :] = extract_features(X_train[i], freqs)\n",
    "\n",
    "    # training labels corresponding to X\n",
    "    Y = y_train\n",
    "\n",
    "    # Apply gradient descent\n",
    "    J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-5, 15000)\n",
    "\n",
    "    return J, theta\n",
    "\n",
    "\n",
    "J, theta = train_logistic_regression(freqs, X_train, y_train)\n",
    "\n",
    "print(f\"The cost after training is {J:.8f}.\")\n",
    "\n",
    "print(\n",
    "    f\"The resulting weight vector is {[round(t, 8) for t in np.squeeze(theta)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict whether a title is positive or negative.\n",
    "def predict_logistic_regression(title, freqs, theta):\n",
    "    # extract the features of the title and store it into x\n",
    "    x = extract_features(title, freqs)\n",
    "    # make the prediction using the features and theta\n",
    "    y_pred = sigmoid(np.dot(x, theta))\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistics Regression Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model's accuracy = 0.9193\n"
     ]
    }
   ],
   "source": [
    "# Given the test data and the weights of the trained model,\n",
    "# Use predict() function to make predictions on each title in the test set.\n",
    "# Get accuracy\n",
    "def logisticRegression(X_test, y_test, freqs, theta):\n",
    "    # the list for storing predictions\n",
    "    y_hat = []\n",
    "\n",
    "    for title in X_test:\n",
    "        # get the label prediction for the title\n",
    "        y_pred = predict_logistic_regression(title, freqs, theta)\n",
    "\n",
    "        if y_pred > 0.5:\n",
    "            # pred > 0.5 then append 1.0 to the list\n",
    "            y_hat.append(1.0)\n",
    "        else:\n",
    "            # pred < 0.5 then append 0 to the list\n",
    "            y_hat.append(0.0)\n",
    "\n",
    "    # y_hat is a list, but y_test is (m,1) array\n",
    "    # convert both to one-dimensional arrays in order to compare them\n",
    "    # squeeze: Remove single-dimensional entries from the shape of an array.\n",
    "    accuracy = (np.array((y_hat)) == np.squeeze(y_test)).mean()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Apply logistic Regression and print model accuracy\n",
    "accuracy = logisticRegression(X_test, y_test, freqs, theta)\n",
    "print(f\"Logistic regression model's accuracy = {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistics Regression</td>\n",
       "      <td>0.919283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy\n",
       "0  Logistics Regression  0.919283"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather Results\n",
    "results = pd.DataFrame([['Logistics Regression', accuracy]],\n",
    "               columns = ['Model', 'Accuracy'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['see', 'dead', 'hedge', 'fund']\n",
      "[[0.35960092]]\n",
      "Negative sentiment\n",
      "\n",
      "['thank', 'mod', 'team', 'glorious', 'retard']\n",
      "[[0.50438049]]\n",
      "Positive sentiment\n",
      "\n",
      "['thank', 'mod']\n",
      "[[0.52373973]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'broker', 'europe']\n",
      "[[0.8278138]]\n",
      "Positive sentiment\n",
      "\n",
      "['wow']\n",
      "[[0.58203296]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'trust']\n",
      "[[0.42377685]]\n",
      "Negative sentiment\n",
      "\n",
      "['free', 'gme']\n",
      "[[0.47086824]]\n",
      "Negative sentiment\n",
      "\n",
      "['robinhood', 'gme', 'wtf']\n",
      "[[0.28024236]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'longer', 'supported', 'robinhood']\n",
      "[[0.27387881]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'great', 'work', 'bois']\n",
      "[[0.55233124]]\n",
      "Positive sentiment\n",
      "\n",
      "['wow', 'robinhood']\n",
      "[[0.50780343]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme']\n",
      "[[0.40068725]]\n",
      "Negative sentiment\n",
      "\n",
      "['wtf', 'rh']\n",
      "[[0.24142725]]\n",
      "Negative sentiment\n",
      "\n",
      "['best', 'trading', 'app']\n",
      "[[0.83913855]]\n",
      "Positive sentiment\n",
      "\n",
      "['cancel', 'robinhood', 'rh', 'screenshot', 'ban']\n",
      "[[0.20301726]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'longer', 'supported', 'robinhood']\n",
      "[[0.27387881]]\n",
      "Negative sentiment\n",
      "\n",
      "['sndl', 'best', 'buy']\n",
      "[[0.83225754]]\n",
      "Positive sentiment\n",
      "\n",
      "['robinhood', 'completely', 'fucked', '’', 'user']\n",
      "[[0.20006457]]\n",
      "Negative sentiment\n",
      "\n",
      "['fucking', 'scam', 'gme']\n",
      "[[0.37481603]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'loss', 'thread', 'pre', 'crash']\n",
      "[[0.12637774]]\n",
      "Negative sentiment\n",
      "\n",
      "['help', 'nok']\n",
      "[[0.58635831]]\n",
      "Positive sentiment\n",
      "\n",
      "['rh', 'market', 'manipulation']\n",
      "[[0.22756582]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'better', 'rise']\n",
      "[[0.63679465]]\n",
      "Positive sentiment\n",
      "\n",
      "['td', 'canada', 'trust', 'webroker']\n",
      "[[0.52148465]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'bad']\n",
      "[[0.5494129]]\n",
      "Positive sentiment\n",
      "\n",
      "['fuck', 'wallstreet', 'fuck', 'robinhood', 'gme', 'amc', 'ftw']\n",
      "[[0.01331062]]\n",
      "Negative sentiment\n",
      "\n",
      "['aa', 'looking', 'good']\n",
      "[[0.61473247]]\n",
      "Positive sentiment\n",
      "\n",
      "['wow', 'guy', 'crazy']\n",
      "[[0.58642408]]\n",
      "Positive sentiment\n",
      "\n",
      "['nok', 'help', 'needed']\n",
      "[[0.5940425]]\n",
      "Positive sentiment\n",
      "\n",
      "['save', 'amc', 'serious']\n",
      "[[0.67963777]]\n",
      "Positive sentiment\n",
      "\n",
      "['stop', 'selling', 'bb']\n",
      "[[0.28809303]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'ok']\n",
      "[[0.57622781]]\n",
      "Positive sentiment\n",
      "\n",
      "['hold', 'gme', 'ffs']\n",
      "[[0.34858294]]\n",
      "Negative sentiment\n",
      "\n",
      "['wow']\n",
      "[[0.58203296]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'shit', 'posting']\n",
      "[[0.32527656]]\n",
      "Negative sentiment\n",
      "\n",
      "['stay', 'strong', 'ppl']\n",
      "[[0.67092731]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', '’', 'panic']\n",
      "[[0.39464689]]\n",
      "Negative sentiment\n",
      "\n",
      "['big', 'loss']\n",
      "[[0.1581798]]\n",
      "Negative sentiment\n",
      "\n",
      "['free', 'homie', 'gme']\n",
      "[[0.47879081]]\n",
      "Negative sentiment\n",
      "\n",
      "['wow', 'screw', 'robinhood']\n",
      "[[0.51574172]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'entertainment']\n",
      "[[0.59714485]]\n",
      "Positive sentiment\n",
      "\n",
      "['fuck', 'gme', 'buy', 'doge']\n",
      "[[0.09839351]]\n",
      "Negative sentiment\n",
      "\n",
      "['yolo', 'prty']\n",
      "[[0.99833943]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'suspended', 'webull']\n",
      "[[0.20929629]]\n",
      "Negative sentiment\n",
      "\n",
      "['boycott', 'restricting', 'u']\n",
      "[[0.43215214]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'trading', 'suspended']\n",
      "[[0.26583821]]\n",
      "Negative sentiment\n",
      "\n",
      "['rh', 'longer', 'support', 'sundial', 'grower']\n",
      "[[0.2372885]]\n",
      "Negative sentiment\n",
      "\n",
      "['rh', 'crashed', 'gain']\n",
      "[[0.753164]]\n",
      "Positive sentiment\n",
      "\n",
      "['screwed', 'u']\n",
      "[[0.45119612]]\n",
      "Negative sentiment\n",
      "\n",
      "['wow', 'fucking', 'sndl', 'buy', 'got', 'yeeted', 'fuck', 'cocksucker']\n",
      "[[0.15275084]]\n",
      "Negative sentiment\n",
      "\n",
      "['sndl', 'lfg', 'fuck', 'robbinghood']\n",
      "[[0.12076933]]\n",
      "Negative sentiment\n",
      "\n",
      "['like', 'bb']\n",
      "[[0.66479207]]\n",
      "Positive sentiment\n",
      "\n",
      "['well', '’', 'fucked', 'boy']\n",
      "[[0.35626689]]\n",
      "Negative sentiment\n",
      "\n",
      "['glory', 'let', '’', 'pretend', 'last', 'number', 'pls', 'gme']\n",
      "[[0.35263713]]\n",
      "Negative sentiment\n",
      "\n",
      "['fuck', 'rh']\n",
      "[[0.05548818]]\n",
      "Negative sentiment\n",
      "\n",
      "['two', 'front', 'war']\n",
      "[[0.44117909]]\n",
      "Negative sentiment\n",
      "\n",
      "['would', 'like', 'nok', 'amc', 'stop', 'falling', 'lmao']\n",
      "[[0.5345265]]\n",
      "Positive sentiment\n",
      "\n",
      "['please', 'help', 'u', 'nakd']\n",
      "[[0.7288398]]\n",
      "Positive sentiment\n",
      "\n",
      "['well', '’', 'livid']\n",
      "[[0.47250131]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'banned']\n",
      "[[0.35689936]]\n",
      "Negative sentiment\n",
      "\n",
      "['ben', 'proud']\n",
      "[[0.50903462]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'way', 'buy', 'dodge']\n",
      "[[0.85100329]]\n",
      "Positive sentiment\n",
      "\n",
      "['im', 'nok', 'number', 'fan']\n",
      "[[0.42993542]]\n",
      "Negative sentiment\n",
      "\n",
      "['free', 'free', 'market', 'info']\n",
      "[[0.6370455]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'looking', 'strong']\n",
      "[[0.76797432]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'need', 'help']\n",
      "[[0.65767534]]\n",
      "Positive sentiment\n",
      "\n",
      "['well']\n",
      "[[0.61680686]]\n",
      "Positive sentiment\n",
      "\n",
      "['stock', 'longer', 'supported', 'rh']\n",
      "[[0.21580115]]\n",
      "Negative sentiment\n",
      "\n",
      "['sndl', 'big', 'gain']\n",
      "[[0.83724454]]\n",
      "Positive sentiment\n",
      "\n",
      "['wtf', 'happening', 'nok']\n",
      "[[0.3936648]]\n",
      "Negative sentiment\n",
      "\n",
      "['expr', 'dead', 'rn']\n",
      "[[0.40133865]]\n",
      "Negative sentiment\n",
      "\n",
      "['merril', 'account', 'blocking', 'gme', 'sad']\n",
      "[[0.32925655]]\n",
      "Negative sentiment\n",
      "\n",
      "['stop', 'selling', 'amc']\n",
      "[[0.33155627]]\n",
      "Negative sentiment\n",
      "\n",
      "['best', 'app', 'instant', 'investment']\n",
      "[[0.85724723]]\n",
      "Positive sentiment\n",
      "\n",
      "['love', 'nok']\n",
      "[[0.61356511]]\n",
      "Positive sentiment\n",
      "\n",
      "['aged', 'well']\n",
      "[[0.62428785]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'share', 'crashing']\n",
      "[[0.84031853]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'ready', 'ape', 'love']\n",
      "[[0.77435431]]\n",
      "Positive sentiment\n",
      "\n",
      "['really', 'sad', 'amc']\n",
      "[[0.51663335]]\n",
      "Positive sentiment\n",
      "\n",
      "['love', 'see']\n",
      "[[0.6505486]]\n",
      "Positive sentiment\n",
      "\n",
      "['hold', 'amc', 'nok', 'bitch']\n",
      "[[0.46663663]]\n",
      "Negative sentiment\n",
      "\n",
      "['fuck', 'rh']\n",
      "[[0.05548818]]\n",
      "Negative sentiment\n",
      "\n",
      "['diamond', 'hand', 'monke', 'man']\n",
      "[[0.6505486]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'stock', 'suspended']\n",
      "[[0.24678914]]\n",
      "Negative sentiment\n",
      "\n",
      "['webull', 'suspended', 'gme']\n",
      "[[0.20929629]]\n",
      "Negative sentiment\n",
      "\n",
      "['rig']\n",
      "[[0.50109274]]\n",
      "Positive sentiment\n",
      "\n",
      "['bbw', 'pls']\n",
      "[[0.53281697]]\n",
      "Positive sentiment\n",
      "\n",
      "['imagine', 'playing', 'best', 'hand', 'still', 'lose', 'game']\n",
      "[[0.86848796]]\n",
      "Positive sentiment\n",
      "\n",
      "['better', 'gme', 'play', 'cant', 'stop', 'trading']\n",
      "[[0.41032895]]\n",
      "Negative sentiment\n",
      "\n",
      "['diamond', 'hand', 'gme']\n",
      "[[0.57020218]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'falling', 'boy', 'fight', 'back']\n",
      "[[0.5199845]]\n",
      "Positive sentiment\n",
      "\n",
      "['let', '’', 'get', 'retarded', '’', 'going', 'full', 'retard', 'bb']\n",
      "[[0.20952078]]\n",
      "Negative sentiment\n",
      "\n",
      "['hate', 'well']\n",
      "[[0.59073595]]\n",
      "Positive sentiment\n",
      "\n",
      "['sum', 'u', 'pretty', 'well']\n",
      "[[0.61239644]]\n",
      "Positive sentiment\n",
      "\n",
      "['new', 'livid', 'bought', 'amc', 'fuck', 'guy']\n",
      "[[0.17367564]]\n",
      "Negative sentiment\n",
      "\n",
      "['dont', 'let', 'vulture', 'win', 'amc']\n",
      "[[0.64824367]]\n",
      "Positive sentiment\n",
      "\n",
      "['like', 'gme']\n",
      "[[0.5309152]]\n",
      "Positive sentiment\n",
      "\n",
      "['webull', 'suspended', 'gme']\n",
      "[[0.20929629]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'suspended', 'webull']\n",
      "[[0.36244708]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'need', 'help']\n",
      "[[0.7019207]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'still', 'going', 'holding', 'strong', 'hoping', 'support']\n",
      "[[0.80518746]]\n",
      "Positive sentiment\n",
      "\n",
      "['wow']\n",
      "[[0.58203296]]\n",
      "Positive sentiment\n",
      "\n",
      "['hl', 'looking', 'pretty', 'sexy', 'right']\n",
      "[[0.62010215]]\n",
      "Positive sentiment\n",
      "\n",
      "['bro', 'help']\n",
      "[[0.60718093]]\n",
      "Positive sentiment\n",
      "\n",
      "['tweet', 'bomb', 'anyone', 'denies', 'u']\n",
      "[[0.41111658]]\n",
      "Negative sentiment\n",
      "\n",
      "['stop', 'selling', 'bb']\n",
      "[[0.28809303]]\n",
      "Negative sentiment\n",
      "\n",
      "['robinhood', 'fucked', 'u']\n",
      "[[0.27164661]]\n",
      "Negative sentiment\n",
      "\n",
      "['poor', 'nok']\n",
      "[[0.3936648]]\n",
      "Negative sentiment\n",
      "\n",
      "['robinhood', 'please', 'review', 'u', 'code', '§', 'manipulation', 'security', 'price', 'thanks']\n",
      "[[0.57956816]]\n",
      "Positive sentiment\n",
      "\n",
      "['failing', 'stop', 'selling', 'amc', 'gme']\n",
      "[[0.23818933]]\n",
      "Negative sentiment\n",
      "\n",
      "['fear', 'u']\n",
      "[[0.41111658]]\n",
      "Negative sentiment\n",
      "\n",
      "['someone', 'please', 'help', 'amc']\n",
      "[[0.82107706]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'longer', 'supported', 'robinhood']\n",
      "[[0.44753938]]\n",
      "Negative sentiment\n",
      "\n",
      "['stop', 'selling', 'gme']\n",
      "[[0.18761715]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'bad']\n",
      "[[0.5494129]]\n",
      "Positive sentiment\n",
      "\n",
      "['love', 'nok']\n",
      "[[0.61356511]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'giving', 'anxiety']\n",
      "[[0.60476373]]\n",
      "Positive sentiment\n",
      "\n",
      "['fuck', '’', 'buy', 'bb', 'fucked']\n",
      "[[0.06773903]]\n",
      "Negative sentiment\n",
      "\n",
      "['stop', 'selling', 'amc']\n",
      "[[0.33155627]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'worth', 'like']\n",
      "[[0.7278114]]\n",
      "Positive sentiment\n",
      "\n",
      "['battle', 'amc']\n",
      "[[0.56286628]]\n",
      "Positive sentiment\n",
      "\n",
      "['thanks', 'keeping', 'safe', 'robinhood']\n",
      "[[0.55300169]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo', 'one', 'share', 'better', 'share']\n",
      "[[0.9998784]]\n",
      "Positive sentiment\n",
      "\n",
      "['fuck', 'rh']\n",
      "[[0.05548818]]\n",
      "Negative sentiment\n",
      "\n",
      "['h', 'l', 'win', 'war']\n",
      "[[0.51238873]]\n",
      "Positive sentiment\n",
      "\n",
      "['fuck', 'mod', 'fuck', 'rh', 'take', 'hit', 'like', 'man', 'fuck', 'right']\n",
      "[[0.0017034]]\n",
      "Negative sentiment\n",
      "\n",
      "['well', 'fun']\n",
      "[[0.69540322]]\n",
      "Positive sentiment\n",
      "\n",
      "['well', 'see']\n",
      "[[0.62107051]]\n",
      "Positive sentiment\n",
      "\n",
      "['better', 'bounce', 'back']\n",
      "[[0.53615665]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'suspended', 'really']\n",
      "[[0.41417262]]\n",
      "Negative sentiment\n",
      "\n",
      "['elon', 'help', 'u']\n",
      "[[0.59291943]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'scare']\n",
      "[[0.36213381]]\n",
      "Negative sentiment\n",
      "\n",
      "['best', 'robinhood', 'alternative']\n",
      "[[0.76972528]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'hurting']\n",
      "[[0.52592623]]\n",
      "Positive sentiment\n",
      "\n",
      "['bought', 'alot', 'amc', 'share', 'hopefully', 'make', 'profit']\n",
      "[[0.91433852]]\n",
      "Positive sentiment\n",
      "\n",
      "['big', 'drop']\n",
      "[[0.38506878]]\n",
      "Negative sentiment\n",
      "\n",
      "['solidarity', 'win', 'gme', 'dont', 'stop']\n",
      "[[0.29888766]]\n",
      "Negative sentiment\n",
      "\n",
      "['trust', 'plan']\n",
      "[[0.5564511]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'time', 'buy', 'amc']\n",
      "[[0.89089657]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'uk', 'app', 'buying']\n",
      "[[0.84869653]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'scare']\n",
      "[[0.36213381]]\n",
      "Negative sentiment\n",
      "\n",
      "['crazy', 'fuck', 'amc']\n",
      "[[0.16478196]]\n",
      "Negative sentiment\n",
      "\n",
      "['stop', 'selling', 'gme']\n",
      "[[0.18761715]]\n",
      "Negative sentiment\n",
      "\n",
      "['stop', 'buying', 'dumbass', 'useless', 'reddit', 'award', 'buy', 'gme']\n",
      "[[0.23344945]]\n",
      "Negative sentiment\n",
      "\n",
      "['nok', 'fucked']\n",
      "[[0.33587728]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'suspended']\n",
      "[[0.44084482]]\n",
      "Negative sentiment\n",
      "\n",
      "['sneaky', 'fucker', 'performed', 'well', 'master']\n",
      "[[0.56414467]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'suspended', 'post', 'nothing', 'google', 'search', 'wtf', 'mate']\n",
      "[[0.17285346]]\n",
      "Negative sentiment\n",
      "\n",
      "['nok', 'isnt', 'banned']\n",
      "[[0.4277215]]\n",
      "Negative sentiment\n",
      "\n",
      "['keep', 'fighting', 'amc']\n",
      "[[0.57066735]]\n",
      "Positive sentiment\n",
      "\n",
      "['stop', 'pushing', 'nok']\n",
      "[[0.28814866]]\n",
      "Negative sentiment\n",
      "\n",
      "['fuck', 'msm']\n",
      "[[0.12126449]]\n",
      "Negative sentiment\n",
      "\n",
      "['cancel', 'robinhood', 'gold']\n",
      "[[0.3893582]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'restricted']\n",
      "[[0.37481603]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'yolo']\n",
      "[[0.99880044]]\n",
      "Positive sentiment\n",
      "\n",
      "['wow', 'great', 'rebrand']\n",
      "[[0.70687989]]\n",
      "Positive sentiment\n",
      "\n",
      "['stay', 'strong', 'gme']\n",
      "[[0.56798563]]\n",
      "Positive sentiment\n",
      "\n",
      "['webull', 'suspended', 'gme']\n",
      "[[0.20929629]]\n",
      "Negative sentiment\n",
      "\n",
      "['please', 'help', 'buy', 'gme', 'stock']\n",
      "[[0.6801197]]\n",
      "Positive sentiment\n",
      "\n",
      "['trading', 'apps', 'fucked', 'u']\n",
      "[[0.33887795]]\n",
      "Negative sentiment\n",
      "\n",
      "['rich', 'killing', 'poor', 'robinhood', 'restricts', 'trading', 'company', 'targeted', 'reddit', 'user']\n",
      "[[0.30326232]]\n",
      "Negative sentiment\n",
      "\n",
      "['cancel', 'robinhood', 'gold']\n",
      "[[0.3893582]]\n",
      "Negative sentiment\n",
      "\n",
      "['save', 'moon']\n",
      "[[0.61797053]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'discount', 'ever']\n",
      "[[0.83668335]]\n",
      "Positive sentiment\n",
      "\n",
      "['wow', 'true', 'criminal']\n",
      "[[0.62755766]]\n",
      "Positive sentiment\n",
      "\n",
      "['fuck', 'rh']\n",
      "[[0.05548818]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'best', 'value', 'investment', 'market']\n",
      "[[0.90024066]]\n",
      "Positive sentiment\n",
      "\n",
      "['fuck', 'wallstreet', 'buy', 'gme']\n",
      "[[0.09639518]]\n",
      "Negative sentiment\n",
      "\n",
      "['best', 'buy']\n",
      "[[0.8385092]]\n",
      "Positive sentiment\n",
      "\n",
      "['medium', 'blaming', 'loss', 'u']\n",
      "[[0.15102179]]\n",
      "Negative sentiment\n",
      "\n",
      "['rh', 'dirty']\n",
      "[[0.26636782]]\n",
      "Negative sentiment\n",
      "\n",
      "['im', 'pissed', 'wan', 'na', 'cry']\n",
      "[[0.3328898]]\n",
      "Negative sentiment\n",
      "\n",
      "['honest', 'question', 'rh']\n",
      "[[0.31495915]]\n",
      "Negative sentiment\n",
      "\n",
      "['fuck', 'rh']\n",
      "[[0.05548818]]\n",
      "Negative sentiment\n",
      "\n",
      "['well', '’', 'age', 'well']\n",
      "[[0.62300432]]\n",
      "Positive sentiment\n",
      "\n",
      "['diamond', 'hand', 'diamond', 'sol']\n",
      "[[0.73427135]]\n",
      "Positive sentiment\n",
      "\n",
      "['dad', 'panic', 'sold', 'bb']\n",
      "[[0.49301473]]\n",
      "Negative sentiment\n",
      "\n",
      "['beautiful', 'afternoon', 'sexy', 'gme', 'gamma', 'squeeze']\n",
      "[[0.51054798]]\n",
      "Positive sentiment\n",
      "\n",
      "['tastyworks', 'suspended', 'buying', 'gme']\n",
      "[[0.2570598]]\n",
      "Negative sentiment\n",
      "\n",
      "['dear', 'wall', 'st']\n",
      "[[0.52148465]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'lawsuit']\n",
      "[[0.37481603]]\n",
      "Negative sentiment\n",
      "\n",
      "['back', 'bitch']\n",
      "[[0.43443821]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'banned', 'noc', 'banned', 'get', 'banned']\n",
      "[[0.24678914]]\n",
      "Negative sentiment\n",
      "\n",
      "['ask', 'td', 'love']\n",
      "[[0.62858171]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'feel', 'like', 'good', 'buy']\n",
      "[[0.62036821]]\n",
      "Positive sentiment\n",
      "\n",
      "['trade', 'zero', 'restricting', 'gme', 'go', 'precious', 'diamond', 'hand']\n",
      "[[0.59774263]]\n",
      "Positive sentiment\n",
      "\n",
      "['info', 'requested', 'please']\n",
      "[[0.65674883]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'win']\n",
      "[[0.63470151]]\n",
      "Positive sentiment\n",
      "\n",
      "['big', 'dick', 'energy']\n",
      "[[0.39910384]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'alive']\n",
      "[[0.41603796]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'halted', 'fuck', 'sec', 'fuck', 'robinhood', 'manipulation', 'stop']\n",
      "[[0.0032935]]\n",
      "Negative sentiment\n",
      "\n",
      "['yes', 'gme']\n",
      "[[0.41603796]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'suspended', 'webull']\n",
      "[[0.20929629]]\n",
      "Negative sentiment\n",
      "\n",
      "['stockpile', 'hiding', 'gme']\n",
      "[[0.37481603]]\n",
      "Negative sentiment\n",
      "\n",
      "['buy', 'hold', 'love', 'rich', 'v', 'poor']\n",
      "[[0.65964653]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'luck']\n",
      "[[0.85331491]]\n",
      "Positive sentiment\n",
      "\n",
      "['help', 'u', 'newbie']\n",
      "[[0.59291943]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'suspended', 'webull']\n",
      "[[0.20929629]]\n",
      "Negative sentiment\n",
      "\n",
      "['save', 'repost']\n",
      "[[0.60286094]]\n",
      "Positive sentiment\n",
      "\n",
      "['sofi', 'blocking', 'amc']\n",
      "[[0.5494129]]\n",
      "Positive sentiment\n",
      "\n",
      "['’', 'sitting', 'cry', 'love', 'fuck']\n",
      "[[0.1010469]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'suspended']\n",
      "[[0.26851937]]\n",
      "Negative sentiment\n",
      "\n",
      "['best', 'alternative', 'rh']\n",
      "[[0.64523901]]\n",
      "Positive sentiment\n",
      "\n",
      "['nok', 'great', 'buy']\n",
      "[[0.63482725]]\n",
      "Positive sentiment\n",
      "\n",
      "['value', 'lost', 'minute', 'low', 'volume']\n",
      "[[0.49534192]]\n",
      "Negative sentiment\n",
      "\n",
      "['td', 'ameritrade', 'wtf']\n",
      "[[0.39588922]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'courage', 'retard']\n",
      "[[0.37475248]]\n",
      "Negative sentiment\n",
      "\n",
      "['share', 'bb']\n",
      "[[0.8360091]]\n",
      "Positive sentiment\n",
      "\n",
      "['rich', 'played', 'u', 'played', 'u']\n",
      "[[0.50198529]]\n",
      "Positive sentiment\n",
      "\n",
      "['next', 'best', 'app', 'invest']\n",
      "[[0.85159257]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'app', 'use']\n",
      "[[0.84518147]]\n",
      "Positive sentiment\n",
      "\n",
      "['webull', 'fucked', 'u', 'funny', 'leave', 'lawsuit', 'manipulation']\n",
      "[[0.17387032]]\n",
      "Negative sentiment\n",
      "\n",
      "['fuck', 'rh']\n",
      "[[0.05548818]]\n",
      "Negative sentiment\n",
      "\n",
      "['best', 'stock', 'buy', 'rn']\n",
      "[[0.8271105]]\n",
      "Positive sentiment\n",
      "\n",
      "['poor', 'retard', 'bought', 'amc', 'gme']\n",
      "[[0.41670785]]\n",
      "Negative sentiment\n",
      "\n",
      "['shit', 'response', 'formal', 'complaint', 'ill', 'retard', 'damn', 'well', 'please', 'asshats']\n",
      "[[0.52681631]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'crossover', 'year']\n",
      "[[0.8278138]]\n",
      "Positive sentiment\n",
      "\n",
      "['rh', 'restricted', 'list']\n",
      "[[0.25585334]]\n",
      "Negative sentiment\n",
      "\n",
      "['well', 'well', 'well', '’', 'slap', 'face']\n",
      "[[0.72136306]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'restriction']\n",
      "[[0.37481603]]\n",
      "Negative sentiment\n",
      "\n",
      "['fuck', 'jp', 'morgan', 'silver']\n",
      "[[0.11327196]]\n",
      "Negative sentiment\n",
      "\n",
      "['aged', 'well']\n",
      "[[0.62428785]]\n",
      "Positive sentiment\n",
      "\n",
      "['tried', 'best', 'guy']\n",
      "[[0.82909836]]\n",
      "Positive sentiment\n",
      "\n",
      "['tendie', 'man', 'keep', 'diamond', 'hand']\n",
      "[[0.65260064]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'broker', 'uk', 'join', 'diamond', 'army']\n",
      "[[0.87658795]]\n",
      "Positive sentiment\n",
      "\n",
      "['hero', 'rise', 'little', 'tribute', 'true', 'hero', 'mankind', 'udeepfuckingvalue', 'love', 'man']\n",
      "[[0.73952852]]\n",
      "Positive sentiment\n",
      "\n",
      "['everyday', 'post', 'get', 'better', 'better']\n",
      "[[0.52592623]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'short', 'interest', 'data', '—', 'squeeze', 'begun']\n",
      "[[0.91155146]]\n",
      "Positive sentiment\n",
      "\n",
      "['sad', 'gme', 'story']\n",
      "[[0.35169885]]\n",
      "Negative sentiment\n",
      "\n",
      "['punish', 'rh']\n",
      "[[0.27715347]]\n",
      "Negative sentiment\n",
      "\n",
      "['mic', 'drop']\n",
      "[[0.44679086]]\n",
      "Negative sentiment\n",
      "\n",
      "['nok', 'need', 'love']\n",
      "[[0.61570603]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'app', 'uk']\n",
      "[[0.84929332]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'play']\n",
      "[[0.67382438]]\n",
      "Positive sentiment\n",
      "\n",
      "['friendly', 'reminder', 'gme']\n",
      "[[0.41603796]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'party']\n",
      "[[0.42377685]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'autist', 'love', 'story']\n",
      "[[0.55902618]]\n",
      "Positive sentiment\n",
      "\n",
      "['angry', 'cnn', 'man', 'battle', 'tendies', 'virgindemon', 'colorized']\n",
      "[[0.39805298]]\n",
      "Negative sentiment\n",
      "\n",
      "['mod', 'please', 'make', 'sure', 'wsbs', 'culture', 'remains', 'intact']\n",
      "[[0.68769125]]\n",
      "Positive sentiment\n",
      "\n",
      "['yesterday', '’', 'gain', 'saved', 'huge', 'loss', 'bb']\n",
      "[[0.6206875]]\n",
      "Positive sentiment\n",
      "\n",
      "['original', 'rebel', 'alliance', 'well', 'sure', 'wear', 'helmet']\n",
      "[[0.61894098]]\n",
      "Positive sentiment\n",
      "\n",
      "['rh', 'gme', 'fuck', 'accidental', 'diamond', 'hand']\n",
      "[[0.07416377]]\n",
      "Negative sentiment\n",
      "\n",
      "['fuck', 'rh', 'market', 'manipulation']\n",
      "[[0.04099351]]\n",
      "Negative sentiment\n",
      "\n",
      "['trust', 'diamond', 'hand', 'hold', 'gme']\n",
      "[[0.56569973]]\n",
      "Positive sentiment\n",
      "\n",
      "['eat', 'rich']\n",
      "[[0.49424608]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'million', 'share', 'outstanding', 'million', 'user', 'share', 'per', 'user']\n",
      "[[0.93897258]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'great', 'wealth', 'reset']\n",
      "[[0.54446296]]\n",
      "Positive sentiment\n",
      "\n",
      "['nice', 'headline', 'nyt']\n",
      "[[0.51697195]]\n",
      "Positive sentiment\n",
      "\n",
      "['prisoner', 'dilemma', 'gme']\n",
      "[[0.37481603]]\n",
      "Negative sentiment\n",
      "\n",
      "['nok', 'nok', 'loss']\n",
      "[[0.16178738]]\n",
      "Negative sentiment\n",
      "\n",
      "['current', 'fear', 'mongering', 'post']\n",
      "[[0.38183135]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'prisoner', 'dilemma']\n",
      "[[0.37481603]]\n",
      "Negative sentiment\n",
      "\n",
      "['leave', 'rh']\n",
      "[[0.26636782]]\n",
      "Negative sentiment\n",
      "\n",
      "['obfuscation', 'misinformation', 'propaganda', 'gme']\n",
      "[[0.36213381]]\n",
      "Negative sentiment\n",
      "\n",
      "['well', 'awkward']\n",
      "[[0.62428785]]\n",
      "Positive sentiment\n",
      "\n",
      "['fake', 'news', 'robinhood', 'protected', 'user', 'agreement']\n",
      "[[0.4277215]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'devil', 'advocate']\n",
      "[[0.33735067]]\n",
      "Negative sentiment\n",
      "\n",
      "['poor', 'shorties', 'shitting', 'pant', 'thought', 'could', 'scare', 'u', 'fuck', 'em', 'holding', 'strong']\n",
      "[[0.13640565]]\n",
      "Negative sentiment\n",
      "\n",
      "['great', 'dd', 'rgme']\n",
      "[[0.73778364]]\n",
      "Positive sentiment\n",
      "\n",
      "['well', 'done', 'young', 'lad', 'well', 'done']\n",
      "[[0.76885096]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'know', 'enemy']\n",
      "[[0.36213381]]\n",
      "Negative sentiment\n",
      "\n",
      "['self', 'interest', 'v', 'collective', 'good']\n",
      "[[0.67987391]]\n",
      "Positive sentiment\n",
      "\n",
      "['next', 'big', 'dick', 'play', 'fuck', 'rh']\n",
      "[[0.06040477]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'short', 'interest']\n",
      "[[0.71782486]]\n",
      "Positive sentiment\n",
      "\n",
      "['holding', 'share', 'gme']\n",
      "[[0.7976942]]\n",
      "Positive sentiment\n",
      "\n",
      "['possible', 'gme', 'risk']\n",
      "[[0.37693647]]\n",
      "Negative sentiment\n",
      "\n",
      "['fud', 'hold', 'gme']\n",
      "[[0.33631085]]\n",
      "Negative sentiment\n",
      "\n",
      "['nok', 'holding', 'strong']\n",
      "[[0.68568824]]\n",
      "Positive sentiment\n",
      "\n",
      "['collapse', 'big', 'player']\n",
      "[[0.4244392]]\n",
      "Negative sentiment\n",
      "\n",
      "['nok', 'nok', 'bitch']\n",
      "[[0.37320774]]\n",
      "Negative sentiment\n",
      "\n",
      "['good', 'hedge', 'v', 'bad', 'hedge']\n",
      "[[0.50554413]]\n",
      "Positive sentiment\n",
      "\n",
      "['nok', 'going', 'strong']\n",
      "[[0.62640554]]\n",
      "Positive sentiment\n",
      "\n",
      "['miracle', 'wall', 'st']\n",
      "[[0.48972786]]\n",
      "Negative sentiment\n",
      "\n",
      "['new', 'war', 'begin']\n",
      "[[0.40351229]]\n",
      "Negative sentiment\n",
      "\n",
      "['td', 'ameritrade', 'censored', 'hurt', 'retailer']\n",
      "[[0.41450165]]\n",
      "Negative sentiment\n",
      "\n",
      "['love', 'belgium', 'hold', 'gme']\n",
      "[[0.52859595]]\n",
      "Positive sentiment\n",
      "\n",
      "['trickery', 'gme', 'attack', 'explained']\n",
      "[[0.34964071]]\n",
      "Negative sentiment\n",
      "\n",
      "['loss', 'porn', 'still', 'holding', 'absolute', 'fuck', '’', 'forced', 'stop', 'loss', '’', 'control', 'u']\n",
      "[[0.00132595]]\n",
      "Negative sentiment\n",
      "\n",
      "['robinhood', 'restricting', 'share', 'hold', 'amc', 'bitch', 'shit']\n",
      "[[0.68433273]]\n",
      "Positive sentiment\n",
      "\n",
      "['retard', 'alert', 'amc', 'required', 'love']\n",
      "[[0.71403808]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'yolo', 'hand', 'joined', 'late']\n",
      "[[0.99923773]]\n",
      "Positive sentiment\n",
      "\n",
      "['fun']\n",
      "[[0.58755261]]\n",
      "Positive sentiment\n",
      "\n",
      "['nok', 'dead', 'body']\n",
      "[[0.34300089]]\n",
      "Negative sentiment\n",
      "\n",
      "['pay', 'attention', 'concerning', 'fake', 'news']\n",
      "[[0.4704517]]\n",
      "Negative sentiment\n",
      "\n",
      "['pltr', 'yolo', 'update']\n",
      "[[0.99980021]]\n",
      "Positive sentiment\n",
      "\n",
      "['think', 'lol', 'gme']\n",
      "[[0.41052582]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'holding', 'strong']\n",
      "[[0.78219924]]\n",
      "Positive sentiment\n",
      "\n",
      "['loss', 'porn', 'gme']\n",
      "[[0.1071787]]\n",
      "Negative sentiment\n",
      "\n",
      "['loss', 'gme', 'holding', 'strong']\n",
      "[[0.29877401]]\n",
      "Negative sentiment\n",
      "\n",
      "['eat', 'dick', 'melvin']\n",
      "[[0.39588922]]\n",
      "Negative sentiment\n",
      "\n",
      "['pay', 'attention', 'shit']\n",
      "[[0.40133865]]\n",
      "Negative sentiment\n",
      "\n",
      "['comprehensive', 'gme', 'diamond', 'hand', 'strategy', 'guide']\n",
      "[[0.59338835]]\n",
      "Positive sentiment\n",
      "\n",
      "['ugh', 'feel', 'bit', 'sick']\n",
      "[[0.44340869]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'devil', 'advocate']\n",
      "[[0.33735067]]\n",
      "Negative sentiment\n",
      "\n",
      "['diamond', 'hand', 'gme']\n",
      "[[0.57020218]]\n",
      "Positive sentiment\n",
      "\n",
      "['hold', 'amc', 'stand', 'strong']\n",
      "[[0.70283711]]\n",
      "Positive sentiment\n",
      "\n",
      "['wow']\n",
      "[[0.58203296]]\n",
      "Positive sentiment\n",
      "\n",
      "['save']\n",
      "[[0.60286094]]\n",
      "Positive sentiment\n",
      "\n",
      "['mom', 'support', 'u']\n",
      "[[0.47488998]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'reassurance', 'hold']\n",
      "[[0.38119145]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'gain']\n",
      "[[0.82995472]]\n",
      "Positive sentiment\n",
      "\n",
      "['buying', 'dip', 'yes', 'please', 'gme']\n",
      "[[0.58237367]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'depressed']\n",
      "[[0.38767246]]\n",
      "Negative sentiment\n",
      "\n",
      "['might', 'well']\n",
      "[[0.62428785]]\n",
      "Positive sentiment\n",
      "\n",
      "['low', 'gme']\n",
      "[[0.37693647]]\n",
      "Negative sentiment\n",
      "\n",
      "['ill', 'die', 'hill', 'gme']\n",
      "[[0.3134302]]\n",
      "Negative sentiment\n",
      "\n",
      "['’', 'want', 'u', 'win']\n",
      "[[0.40992447]]\n",
      "Negative sentiment\n",
      "\n",
      "['cnk', 'best', 'revenge']\n",
      "[[0.8278138]]\n",
      "Positive sentiment\n",
      "\n",
      "['loss', 'porn', 'share', 'b']\n",
      "[[0.43969768]]\n",
      "Negative sentiment\n",
      "\n",
      "['im', 'great', 'buying', 'high', 'hell', 'wont', 'sell', 'low', 'sorry', 'break', 'rule', 'im', 'retarded']\n",
      "[[0.34287867]]\n",
      "Negative sentiment\n",
      "\n",
      "['iff', 'update', 'great', 'short', 'squeeze', 'opportunity']\n",
      "[[0.90931828]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'severely', 'undervalued']\n",
      "[[0.41603796]]\n",
      "Negative sentiment\n",
      "\n",
      "['well', 'well']\n",
      "[[0.72064488]]\n",
      "Positive sentiment\n",
      "\n",
      "['psa', 'bb', 'sexy']\n",
      "[[0.56528892]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'financial', 'revolution', 'fight', 'good', 'fight']\n",
      "[[0.32323661]]\n",
      "Negative sentiment\n",
      "\n",
      "['holding', 'strong', 'gme']\n",
      "[[0.62577068]]\n",
      "Positive sentiment\n",
      "\n",
      "['ely', 'look', 'like', 'play']\n",
      "[[0.76161724]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'amc', 'gain']\n",
      "[[0.87465358]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'porn', 'loss']\n",
      "[[0.1071787]]\n",
      "Negative sentiment\n",
      "\n",
      "['comfort', 'uncertain', 'time', 'gme', 'love', 'stock']\n",
      "[[0.5443957]]\n",
      "Positive sentiment\n",
      "\n",
      "['together', 'one', 'stop', 'u']\n",
      "[[0.30227964]]\n",
      "Negative sentiment\n",
      "\n",
      "['pltr', 'yolo', 'please', 'fly', 'soon']\n",
      "[[0.99969256]]\n",
      "Positive sentiment\n",
      "\n",
      "['missing', 'gme']\n",
      "[[0.38767246]]\n",
      "Negative sentiment\n",
      "\n",
      "['money', 'well', 'spent', 'thanks', 'guy', 'reassuring', 'sell']\n",
      "[[0.73062246]]\n",
      "Positive sentiment\n",
      "\n",
      "['lost', 'gme', 'didnt', 'lose', 'dignity']\n",
      "[[0.32227837]]\n",
      "Negative sentiment\n",
      "\n",
      "['may', 'god', 'help', 'u']\n",
      "[[0.6668033]]\n",
      "Positive sentiment\n",
      "\n",
      "['ally', 'invest', 'another', 'enemy']\n",
      "[[0.45689844]]\n",
      "Negative sentiment\n",
      "\n",
      "['spce', 'look', 'strong']\n",
      "[[0.69354291]]\n",
      "Positive sentiment\n",
      "\n",
      "['using', 'best', 'broker', 'sell', 'never']\n",
      "[[0.83480353]]\n",
      "Positive sentiment\n",
      "\n",
      "['fo', 'hold', 'stop', 'selling', 'ffs', 'gme']\n",
      "[[0.14896474]]\n",
      "Negative sentiment\n",
      "\n",
      "['hold', 'u', 'beautiful']\n",
      "[[0.45228186]]\n",
      "Negative sentiment\n",
      "\n",
      "['fuck', 'washington', 'post']\n",
      "[[0.1105501]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'better', 'play', 'reopen']\n",
      "[[0.74968609]]\n",
      "Positive sentiment\n",
      "\n",
      "['rh', 'allow', 'buying', 'fractional', 'share']\n",
      "[[0.65142139]]\n",
      "Positive sentiment\n",
      "\n",
      "['attack', 'wall', 'st', 'worst', 'girl']\n",
      "[[0.4355823]]\n",
      "Negative sentiment\n",
      "\n",
      "['sir', 'mixalot', 'said', 'best']\n",
      "[[0.8278138]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'super', 'awesome', 'megathread', 'wed']\n",
      "[[0.48898243]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'better', 'lose', 'trying', 'round', 'fight']\n",
      "[[0.34752666]]\n",
      "Negative sentiment\n",
      "\n",
      "['like', 'kind', 'party']\n",
      "[[0.65878355]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'calm', 'fuck']\n",
      "[[0.08413215]]\n",
      "Negative sentiment\n",
      "\n",
      "['motivation', 'wednesday', 'gme']\n",
      "[[0.41603796]]\n",
      "Negative sentiment\n",
      "\n",
      "['skt', 'dd', 'tanger', 'outlet', 'mall', 'value', 'play', 'please', 'read']\n",
      "[[0.89785347]]\n",
      "Positive sentiment\n",
      "\n",
      "['spce', 'put', 'yolo']\n",
      "[[0.99855046]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'loss', 'porn']\n",
      "[[0.1071787]]\n",
      "Negative sentiment\n",
      "\n",
      "['nio', 'yolo']\n",
      "[[0.99850374]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'diamond', 'hand', 'feeling', 'softer']\n",
      "[[0.58789201]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'gain', 'everyone', 'fantastic', 'day']\n",
      "[[0.92249974]]\n",
      "Positive sentiment\n",
      "\n",
      "['feel', 'good', 'post', '’', 'cry']\n",
      "[[0.32973586]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'ruined', 'community']\n",
      "[[0.36213381]]\n",
      "Negative sentiment\n",
      "\n",
      "['original', 'post', 'please']\n",
      "[[0.63279233]]\n",
      "Positive sentiment\n",
      "\n",
      "['regarding', 'hold', 'positive', 'motivational', 'word', 'motivate', 'positively', 'post', 'desired', 'outcome']\n",
      "[[0.53384055]]\n",
      "Positive sentiment\n",
      "\n",
      "['weakling', 'among', 'u']\n",
      "[[0.46472497]]\n",
      "Negative sentiment\n",
      "\n",
      "['well', 'hf', 'celebrating', 'right']\n",
      "[[0.63381039]]\n",
      "Positive sentiment\n",
      "\n",
      "['fuck', 'gme', 'pessimism']\n",
      "[[0.08413215]]\n",
      "Negative sentiment\n",
      "\n",
      "['guy', 'best']\n",
      "[[0.82454935]]\n",
      "Positive sentiment\n",
      "\n",
      "['hong', 'kong', 'love', 'gme']\n",
      "[[0.56462239]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'share', 'count']\n",
      "[[0.74420192]]\n",
      "Positive sentiment\n",
      "\n",
      "['well', 'done', 'family']\n",
      "[[0.65359384]]\n",
      "Positive sentiment\n",
      "\n",
      "['rh', 'ruined', 'life']\n",
      "[[0.24729358]]\n",
      "Negative sentiment\n",
      "\n",
      "['retard', 'need', 'pro', 'help']\n",
      "[[0.58854888]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'dead']\n",
      "[[0.48145308]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'open', 'interest']\n",
      "[[0.47086824]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'share']\n",
      "[[0.74420192]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'lost', 'long', 'time']\n",
      "[[0.81446399]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'stock', 'watching', 'apps']\n",
      "[[0.80608622]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo']\n",
      "[[0.99742721]]\n",
      "Positive sentiment\n",
      "\n",
      "['fun', 'trick']\n",
      "[[0.58755261]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'hurt']\n",
      "[[0.57622781]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'confidence', 'post']\n",
      "[[0.38332585]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'holding', 'relaxing']\n",
      "[[0.66765623]]\n",
      "Positive sentiment\n",
      "\n",
      "['cry', 'diamond', 'hand', 'ill', 'die', 'stock', 'sell']\n",
      "[[0.47707683]]\n",
      "Negative sentiment\n",
      "\n",
      "['share', 'amc']\n",
      "[[0.86203997]]\n",
      "Positive sentiment\n",
      "\n",
      "['feel', 'great', 'gme']\n",
      "[[0.52525003]]\n",
      "Positive sentiment\n",
      "\n",
      "['new', 'retard', 'need', 'help']\n",
      "[[0.56414467]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'sale', 'ever']\n",
      "[[0.83668335]]\n",
      "Positive sentiment\n",
      "\n",
      "['thank', 'god', 'gme', 'dropping']\n",
      "[[0.52641067]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'share', 'share']\n",
      "[[0.92679376]]\n",
      "Positive sentiment\n",
      "\n",
      "['big', 'shark', 'win', 'haha']\n",
      "[[0.48740158]]\n",
      "Negative sentiment\n",
      "\n",
      "['post', 'yer', 'loss']\n",
      "[[0.17916491]]\n",
      "Negative sentiment\n",
      "\n",
      "['stop', 'already', 'dead']\n",
      "[[0.23158648]]\n",
      "Negative sentiment\n",
      "\n",
      "['well', 'restriction']\n",
      "[[0.59073595]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'like', 'console']\n",
      "[[0.53881928]]\n",
      "Positive sentiment\n",
      "\n",
      "['got', 'good', 'feeling', 'gme']\n",
      "[[0.4561583]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'dead']\n",
      "[[0.48145308]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'holder', 'crisis']\n",
      "[[0.40068725]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'dead']\n",
      "[[0.30182227]]\n",
      "Negative sentiment\n",
      "\n",
      "['’', 'let', 'greed', 'fear', 'make', 'disregard', 'fact']\n",
      "[[0.31786238]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'valuable']\n",
      "[[0.59714485]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'still', 'great', 'play']\n",
      "[[0.67719248]]\n",
      "Positive sentiment\n",
      "\n",
      "['psth', 'yolo', 'bill', 'spackman', 'ftw']\n",
      "[[0.99836913]]\n",
      "Positive sentiment\n",
      "\n",
      "['clearinghouses', 'fucked', 'u', 'thats', 'ok']\n",
      "[[0.29945625]]\n",
      "Negative sentiment\n",
      "\n",
      "['sup', 'fuck', 'nugget']\n",
      "[[0.11557541]]\n",
      "Negative sentiment\n",
      "\n",
      "['mod', 'bring', 'back', 'hip', 'fire', 'ban', 'hammer']\n",
      "[[0.41005567]]\n",
      "Negative sentiment\n",
      "\n",
      "['respect', 'best', 'family']\n",
      "[[0.8278138]]\n",
      "Positive sentiment\n",
      "\n",
      "['rh', 'retard']\n",
      "[[0.26015323]]\n",
      "Negative sentiment\n",
      "\n",
      "['positivity', 'back']\n",
      "[[0.50218868]]\n",
      "Positive sentiment\n",
      "\n",
      "['ya', 'winning', 'son']\n",
      "[[0.56427803]]\n",
      "Positive sentiment\n",
      "\n",
      "['sompos', 'holding', 'pltr', 'yolo', 'million', 'share']\n",
      "[[0.99990067]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'exposed', 'truth']\n",
      "[[0.41603796]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'buysell', 'pressure', 'strike']\n",
      "[[0.57622781]]\n",
      "Positive sentiment\n",
      "\n",
      "['fuck', 'uoneparkjsung', 'eat', 'dick', 'bitch', 'hahahahah', 'get', 'unmodded']\n",
      "[[0.05548818]]\n",
      "Negative sentiment\n",
      "\n",
      "['losing', 'hope', 'amc', 'call', 'fuck', 'yolo']\n",
      "[[0.99323522]]\n",
      "Positive sentiment\n",
      "\n",
      "['carmat', 'aeson', 'artifical', 'heart', 'dd']\n",
      "[[0.64849098]]\n",
      "Positive sentiment\n",
      "\n",
      "['dear', 'god', 'gme']\n",
      "[[0.51054798]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'short', 'interest']\n",
      "[[0.54222024]]\n",
      "Positive sentiment\n",
      "\n",
      "['showing', 'bb', 'love']\n",
      "[[0.687633]]\n",
      "Positive sentiment\n",
      "\n",
      "['coming', 'back', 'dead']\n",
      "[[0.40239238]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'dead']\n",
      "[[0.48145308]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'sound', 'like']\n",
      "[[0.53881928]]\n",
      "Positive sentiment\n",
      "\n",
      "['cant', 'stop', 'u', 'ape', 'together', 'strong']\n",
      "[[0.5019175]]\n",
      "Positive sentiment\n",
      "\n",
      "['lol', 'wow']\n",
      "[[0.58423019]]\n",
      "Positive sentiment\n",
      "\n",
      "['held', 'share', 'gme', 'since', 'bought', 'yesterday', 'good', 'luck']\n",
      "[[0.86606375]]\n",
      "Positive sentiment\n",
      "\n",
      "['free', 'karma', 'nice', 'see', 'green', 'today']\n",
      "[[0.6370455]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'stop', 'acting', 'like', 'coke', 'dick']\n",
      "[[0.4756451]]\n",
      "Negative sentiment\n",
      "\n",
      "['missed', 'opportunity', 'obsessing', 'gme']\n",
      "[[0.41490747]]\n",
      "Negative sentiment\n",
      "\n",
      "['eat', 'shit', 'jim', 'cramer', 'scared', 'ape']\n",
      "[[0.37115907]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'win']\n",
      "[[0.44720414]]\n",
      "Negative sentiment\n",
      "\n",
      "['blaming', 'u', 'manipulation']\n",
      "[[0.37218283]]\n",
      "Negative sentiment\n",
      "\n",
      "['freaking', 'love', 'amc', 'gme']\n",
      "[[0.63502621]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'amc', 'yolo', 'update', 'strong']\n",
      "[[0.99968714]]\n",
      "Positive sentiment\n",
      "\n",
      "['bought', 'gme', 'share']\n",
      "[[0.7708448]]\n",
      "Positive sentiment\n",
      "\n",
      "['extremely', 'undervalued', 'techclean', 'energy', 'play', 'super', 'cheap', 'call', 'cl']\n",
      "[[0.79224341]]\n",
      "Positive sentiment\n",
      "\n",
      "['god', 'gon', 'na', 'save', 'gme']\n",
      "[[0.5835054]]\n",
      "Positive sentiment\n",
      "\n",
      "['popular', 'interest', 'gme', 'increasing', 'remains', 'strong']\n",
      "[[0.65092859]]\n",
      "Positive sentiment\n",
      "\n",
      "['dear', 'amc', 'warrior']\n",
      "[[0.62730408]]\n",
      "Positive sentiment\n",
      "\n",
      "['well', 'broke', 'mexican', 'got', 'one', 'single', 'share']\n",
      "[[0.86372433]]\n",
      "Positive sentiment\n",
      "\n",
      "['sec', 'complaint', 'filed', 'gme', 'trading', 'abuse']\n",
      "[[0.32227837]]\n",
      "Negative sentiment\n",
      "\n",
      "['sad', 'face', 'gme', 'loss', 'porn']\n",
      "[[0.0887603]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'ape', 'together', 'strong']\n",
      "[[0.59774263]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'fun', 'since', 'lockdown']\n",
      "[[0.87210475]]\n",
      "Positive sentiment\n",
      "\n",
      "['behold', 'gme', 'incompetence']\n",
      "[[0.37481603]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'fuck']\n",
      "[[0.17242098]]\n",
      "Negative sentiment\n",
      "\n",
      "['save', 'amc', 'retard']\n",
      "[[0.6533482]]\n",
      "Positive sentiment\n",
      "\n",
      "['serious', 'warning', 'gme']\n",
      "[[0.36950446]]\n",
      "Negative sentiment\n",
      "\n",
      "['u', 'yolo']\n",
      "[[0.99801759]]\n",
      "Positive sentiment\n",
      "\n",
      "['lol', 'gme', 'stupid', 'af']\n",
      "[[0.35169885]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'gain', 'porn', 'initial', 'investment', 'profit']\n",
      "[[0.82071822]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'amc', 'smell', 'sexy', 'buying', 'opportunity']\n",
      "[[0.56879497]]\n",
      "Positive sentiment\n",
      "\n",
      "['bit', 'delayed', 'oz', 'im', 'fucking', 'retarded', 'cunt']\n",
      "[[0.27990524]]\n",
      "Negative sentiment\n",
      "\n",
      "['psec', 'earnings', 'play', 'gme', 'share', 'yolo']\n",
      "[[0.99976518]]\n",
      "Positive sentiment\n",
      "\n",
      "['please', 'help', 'sell', 'gme']\n",
      "[[0.66418747]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'conspiracy']\n",
      "[[0.38767246]]\n",
      "Negative sentiment\n",
      "\n",
      "['share', 'gme']\n",
      "[[0.74420192]]\n",
      "Positive sentiment\n",
      "\n",
      "['ha', 'ha', 'watching', 'eat', 'alive']\n",
      "[[0.49198681]]\n",
      "Negative sentiment\n",
      "\n",
      "['big', 'medium', 'fear', 'mongering']\n",
      "[[0.32287098]]\n",
      "Negative sentiment\n",
      "\n",
      "['gm', 'super', 'bowl', 'ad', 'disaster', 'marketing']\n",
      "[[0.47721214]]\n",
      "Negative sentiment\n",
      "\n",
      "['horrible', 'mess', 'big', 'ugly', 'hedge']\n",
      "[[0.36694967]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'fatigue']\n",
      "[[0.37481603]]\n",
      "Negative sentiment\n",
      "\n",
      "['fresh', 'bb']\n",
      "[[0.54737585]]\n",
      "Positive sentiment\n",
      "\n",
      "['rh', 'getting', 'desperate']\n",
      "[[0.26636782]]\n",
      "Negative sentiment\n",
      "\n",
      "['love', 'holding', 'gme']\n",
      "[[0.62255835]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'fatigue']\n",
      "[[0.37481603]]\n",
      "Negative sentiment\n",
      "\n",
      "['went', 'paper', 'hand', 'losing', 'year', 'profit', 'yolo', 'account', 'fed', 'credit', 'card', 'reward', 'fun', 'sad']\n",
      "[[0.99936474]]\n",
      "Positive sentiment\n",
      "\n",
      "['rh', 'hate', 'dumb', 'misguided']\n",
      "[[0.24561495]]\n",
      "Negative sentiment\n",
      "\n",
      "['best', 'buy', 'bby', 'dd', 'earnings', 'play']\n",
      "[[0.95495016]]\n",
      "Positive sentiment\n",
      "\n",
      "['fyi', 'gme']\n",
      "[[0.40834025]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'gain', 'porn']\n",
      "[[0.77474098]]\n",
      "Positive sentiment\n",
      "\n",
      "['mmm', 'cheap', 'fuck']\n",
      "[[0.13441624]]\n",
      "Negative sentiment\n",
      "\n",
      "['nvta', 'yolo']\n",
      "[[0.99828592]]\n",
      "Positive sentiment\n",
      "\n",
      "['thanks', 'gme']\n",
      "[[0.49466401]]\n",
      "Negative sentiment\n",
      "\n",
      "['winning', 'son']\n",
      "[[0.54859605]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'gain']\n",
      "[[0.82995472]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'gain']\n",
      "[[0.82995472]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'gain']\n",
      "[[0.82995472]]\n",
      "Positive sentiment\n",
      "\n",
      "['safe', 'show', 'amc', 'gain']\n",
      "[[0.92249974]]\n",
      "Positive sentiment\n",
      "\n",
      "['vsto', 'dd', 'great', 'value', 'play', 'vista', 'outdoors']\n",
      "[[0.88233614]]\n",
      "Positive sentiment\n",
      "\n",
      "['wow', 'super', 'bowl', 'commercial', 'u']\n",
      "[[0.59727532]]\n",
      "Positive sentiment\n",
      "\n",
      "['warning', 'gme', 'discussion']\n",
      "[[0.36213381]]\n",
      "Negative sentiment\n",
      "\n",
      "['feel', 'good', 'man']\n",
      "[[0.53274946]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'gain', 'porn']\n",
      "[[0.77474098]]\n",
      "Positive sentiment\n",
      "\n",
      "['perfect', 'trading', 'plan']\n",
      "[[0.53731412]]\n",
      "Positive sentiment\n",
      "\n",
      "['value', 'earnings', 'play', 'bio']\n",
      "[[0.77137131]]\n",
      "Positive sentiment\n",
      "\n",
      "['wsb', 'gme', 'infinity', 'war']\n",
      "[[0.33429633]]\n",
      "Negative sentiment\n",
      "\n",
      "['free', 'money', 'alert', 'semiconductor', 'exp']\n",
      "[[0.61473247]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'retard', 'road']\n",
      "[[0.35476536]]\n",
      "Negative sentiment\n",
      "\n",
      "['iwm', 'call', 'looking', 'like', 'super', 'tasty', 'tendies', 'super', 'short', 'dd']\n",
      "[[0.89446396]]\n",
      "Positive sentiment\n",
      "\n",
      "['psa', 'stop', 'betting', 'smart', 'money', 'dumb', 'company']\n",
      "[[0.27985058]]\n",
      "Negative sentiment\n",
      "\n",
      "['lumn', 'loss']\n",
      "[[0.2089749]]\n",
      "Negative sentiment\n",
      "\n",
      "['dfv', '’', 'den', 'love']\n",
      "[[0.53942572]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['welcome', 'back', 'king']\n",
      "[[0.52599384]]\n",
      "Positive sentiment\n",
      "\n",
      "['welcome', 'back', 'zjz']\n",
      "[[0.51806656]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'seems', 'like', 'great', 'opportunity', 'buy', 'dip']\n",
      "[[0.92382053]]\n",
      "Positive sentiment\n",
      "\n",
      "['nrg', 'trouble']\n",
      "[[0.50109274]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['dow', 'yolo', 'dis', 'nasdaq', 'yolo', 'sq']\n",
      "[[0.99999707]]\n",
      "Positive sentiment\n",
      "\n",
      "['welcome', 'new', 'money']\n",
      "[[0.50444828]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'blockbuster', 'dd']\n",
      "[[0.70568919]]\n",
      "Positive sentiment\n",
      "\n",
      "['lmt', 'cathy', 'approves']\n",
      "[[0.50109274]]\n",
      "Positive sentiment\n",
      "\n",
      "['unfi', 'yolo', 'february']\n",
      "[[0.99896829]]\n",
      "Positive sentiment\n",
      "\n",
      "['red', 'crayon', 'taste', 'best']\n",
      "[[0.81990555]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'yuge', 'short', 'interest', 'yuge', 'fcf', 'free', 'cash', 'flow', 'earnings', 'next', 'week', 'huge', 'share', 'buy', 'back', 'progress']\n",
      "[[0.98020649]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'biotech', 'sava', 'dd']\n",
      "[[0.88606555]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'loss']\n",
      "[[0.41310936]]\n",
      "Negative sentiment\n",
      "\n",
      "['got', 'ta', 'love', 'bang', 'p']\n",
      "[[0.66989874]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'loss']\n",
      "[[0.1455597]]\n",
      "Negative sentiment\n",
      "\n",
      "['fvrr', 'yolo']\n",
      "[[0.99839128]]\n",
      "Positive sentiment\n",
      "\n",
      "['fvrr', 'yolo', 'like', 'stock']\n",
      "[[0.99893473]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo', 'insane', 'value', 'play', 'cathiekarp', 'love', 'yall']\n",
      "[[0.99987134]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo', 'love', 'cathie']\n",
      "[[0.99966788]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'ddiiiiiiiiiiideep', 'value']\n",
      "[[0.62428785]]\n",
      "Positive sentiment\n",
      "\n",
      "['forst', 'yolo', 'gme', 'god', 'bless', 'dfv']\n",
      "[[0.99829625]]\n",
      "Positive sentiment\n",
      "\n",
      "['thank', 'pltr', 'cool']\n",
      "[[0.76404564]]\n",
      "Positive sentiment\n",
      "\n",
      "['loss', 'gme']\n",
      "[[0.1455597]]\n",
      "Negative sentiment\n",
      "\n",
      "['pltr', 'loss']\n",
      "[[0.41310936]]\n",
      "Negative sentiment\n",
      "\n",
      "['cry']\n",
      "[[0.42002915]]\n",
      "Negative sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo', 'call']\n",
      "[[0.99947724]]\n",
      "Positive sentiment\n",
      "\n",
      "['uber', 'yolo', 'update']\n",
      "[[0.9995006]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'yolo']\n",
      "[[0.9985301]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['well', 'guy', 'fun']\n",
      "[[0.71055576]]\n",
      "Positive sentiment\n",
      "\n",
      "['vrt', 'preer', 'yolo']\n",
      "[[0.99839128]]\n",
      "Positive sentiment\n",
      "\n",
      "['loss', 'gme', 'loss']\n",
      "[[0.04160186]]\n",
      "Negative sentiment\n",
      "\n",
      "['pltr', 'help']\n",
      "[[0.81783425]]\n",
      "Positive sentiment\n",
      "\n",
      "['well', 'well', 'well']\n",
      "[[0.80522999]]\n",
      "Positive sentiment\n",
      "\n",
      "['big', 'dick', 'gain']\n",
      "[[0.803894]]\n",
      "Positive sentiment\n",
      "\n",
      "['uber', 'yolo']\n",
      "[[0.99844151]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'yolo']\n",
      "[[0.99906174]]\n",
      "Positive sentiment\n",
      "\n",
      "['nio', 'yolo', 'feb']\n",
      "[[0.99850374]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'help']\n",
      "[[0.81783425]]\n",
      "Positive sentiment\n",
      "\n",
      "['mac', 'dd', 'potential', 'deep', 'value', 'play']\n",
      "[[0.82187903]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'rkt', 'short', 'huge', 'institution', 'ownership', 'breakoit', 'hopefully', 'soon', 'haha']\n",
      "[[0.99945308]]\n",
      "Positive sentiment\n",
      "\n",
      "['wfc', 'leap', 'gain']\n",
      "[[0.89577498]]\n",
      "Positive sentiment\n",
      "\n",
      "['got', 'inspired', 'charity', 'post', 'thanks', 'everyone', 'donating', 'food', 'bank', 'hospital', 'charity', 'spread', 'love']\n",
      "[[0.71520863]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'yolo', 'please', 'go']\n",
      "[[0.99927535]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo']\n",
      "[[0.9992454]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'fucked']\n",
      "[[0.45432023]]\n",
      "Negative sentiment\n",
      "\n",
      "['gain', 'pltr', 'love', 'stonk']\n",
      "[[0.97507362]]\n",
      "Positive sentiment\n",
      "\n",
      "['making', 'meme', 'fun']\n",
      "[[0.61797053]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'yolo', 'part', 'ii', 'kickstart', 'heart']\n",
      "[[0.99887421]]\n",
      "Positive sentiment\n",
      "\n",
      "['well', 'fuck']\n",
      "[[0.18933147]]\n",
      "Negative sentiment\n",
      "\n",
      "['first', 'big', 'gain', 'ever', 'thanks', 'ape']\n",
      "[[0.92157386]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['nclh', 'yolo', 'update']\n",
      "[[0.9995006]]\n",
      "Positive sentiment\n",
      "\n",
      "['tc', 'energy', 'trpto', 'making', 'mad', 'profit', 'due', 'texas', 'freeze']\n",
      "[[0.64955135]]\n",
      "Positive sentiment\n",
      "\n",
      "['uber', 'yolo']\n",
      "[[0.99844151]]\n",
      "Positive sentiment\n",
      "\n",
      "['ag', 'gain', 'porn']\n",
      "[[0.85037759]]\n",
      "Positive sentiment\n",
      "\n",
      "['ni', 'nisource', 'last', 'value', 'clean', 'energy']\n",
      "[[0.67092731]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo', 'update']\n",
      "[[0.99980021]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'yolo']\n",
      "[[0.99880044]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo', 'update']\n",
      "[[0.99975833]]\n",
      "Positive sentiment\n",
      "\n",
      "['help', 'u', 'jpow', 'youre', 'hope']\n",
      "[[0.59727532]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'recovery', 'play']\n",
      "[[0.71688102]]\n",
      "Positive sentiment\n",
      "\n",
      "['zuo', 'yolo', 'dd']\n",
      "[[0.9989728]]\n",
      "Positive sentiment\n",
      "\n",
      "['l']\n",
      "[[0.51697195]]\n",
      "Positive sentiment\n",
      "\n",
      "['unfi', 'yolo', 'february']\n",
      "[[0.99896829]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'bought', 'share', 'gmed']\n",
      "[[0.99966952]]\n",
      "Positive sentiment\n",
      "\n",
      "['lolz', 'well', 'worked']\n",
      "[[0.63171]]\n",
      "Positive sentiment\n",
      "\n",
      "['gain', 'porn', 'lfg']\n",
      "[[0.8433095]]\n",
      "Positive sentiment\n",
      "\n",
      "['welcome', 'next', 'round', 'gme', 'love', 'stonks']\n",
      "[[0.60208155]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'like', 'free', 'money']\n",
      "[[0.80817571]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'high', 'risk', 'high', 'reward', 'play']\n",
      "[[0.56455573]]\n",
      "Positive sentiment\n",
      "\n",
      "['gain', 'gme', 'round', 'played', 'good']\n",
      "[[0.86710877]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'automotive', 'gold', 'winner', 'cybersecurity', 'excellence', 'award']\n",
      "[[0.55408507]]\n",
      "Positive sentiment\n",
      "\n",
      "['hi', 'im', 'stupid']\n",
      "[[0.38831641]]\n",
      "Negative sentiment\n",
      "\n",
      "['thanks', 'gme']\n",
      "[[0.49466401]]\n",
      "Negative sentiment\n",
      "\n",
      "['buying', 'gme', 'top', 'yesterday', 'wish', 'luck']\n",
      "[[0.64052837]]\n",
      "Positive sentiment\n",
      "\n",
      "['pbr', 'yolo']\n",
      "[[0.99833943]]\n",
      "Positive sentiment\n",
      "\n",
      "['unfi', 'united', 'natural', 'food', 'yolo', 'update', 'february', 'going']\n",
      "[[0.99972058]]\n",
      "Positive sentiment\n",
      "\n",
      "['well', 'still', 'fucked']\n",
      "[[0.49746591]]\n",
      "Negative sentiment\n",
      "\n",
      "['pltr', 'yolo', 'still', 'chance', 'profit']\n",
      "[[0.99954374]]\n",
      "Positive sentiment\n",
      "\n",
      "['easy', 'dd', 'like', 'eating', 'banana', 'vxx', 'uvxy']\n",
      "[[0.76325442]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'special', 'dividend', 'coming', 'share', 'buyback', 'coming', 'high', 'short', 'interest']\n",
      "[[0.95046121]]\n",
      "Positive sentiment\n",
      "\n",
      "['fuck', 'amc', 'dd']\n",
      "[[0.25206865]]\n",
      "Negative sentiment\n",
      "\n",
      "['super', 'top', 'secret', 'illegal', 'pltr', 'palantir', 'cat', 'chart']\n",
      "[[0.814423]]\n",
      "Positive sentiment\n",
      "\n",
      "['hedgefund', 'increase', 'gme', 'short', 'interest']\n",
      "[[0.57355488]]\n",
      "Positive sentiment\n",
      "\n",
      "['well', 'shit']\n",
      "[[0.53717927]]\n",
      "Positive sentiment\n",
      "\n",
      "['fuck', 'rkt', 'share', 'gme', 'share', 'amc', 'share']\n",
      "[[0.95432386]]\n",
      "Positive sentiment\n",
      "\n",
      "['nio', 'yolo', 'update']\n",
      "[[0.99952056]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'gain', 'part']\n",
      "[[0.83439173]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'bull', 'trap']\n",
      "[[0.56286628]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'gain']\n",
      "[[0.82995472]]\n",
      "Positive sentiment\n",
      "\n",
      "['like', 'father', 'like', 'son']\n",
      "[[0.75997231]]\n",
      "Positive sentiment\n",
      "\n",
      "['ride', 'die', 'pltr']\n",
      "[[0.69633099]]\n",
      "Positive sentiment\n",
      "\n",
      "['portfolio', 'pltr', 'yolo']\n",
      "[[0.99939561]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'loss', 'porn']\n",
      "[[0.1071787]]\n",
      "Negative sentiment\n",
      "\n",
      "['doctor', 'wish', 'u', 'retard', 'best', 'luck']\n",
      "[[0.8855398]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo', 'update']\n",
      "[[0.99975833]]\n",
      "Positive sentiment\n",
      "\n",
      "['nok', 'yolo']\n",
      "[[0.99802677]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'week', 'poor', 'retarded', 'life']\n",
      "[[0.68857385]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'saved', 'account', 'gme', 'diamond', 'hand', 'life', 'cheer', 'glorious', 'retard']\n",
      "[[0.68593162]]\n",
      "Positive sentiment\n",
      "\n",
      "['worth', 'gme', 'promised', 'boy']\n",
      "[[0.42043649]]\n",
      "Negative sentiment\n",
      "\n",
      "['team', 'rkt', 'yolo']\n",
      "[[0.99909106]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'rkt']\n",
      "[[0.99906174]]\n",
      "Positive sentiment\n",
      "\n",
      "['nok', 'looking', 'like', 'strong', 'value', 'buy', 'good', 'growth', 'prospect']\n",
      "[[0.87943412]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'yolo', 'like', 'black', 'berry']\n",
      "[[0.99918463]]\n",
      "Positive sentiment\n",
      "\n",
      "['net', 'worth', 'gme', 'yolo']\n",
      "[[0.99766056]]\n",
      "Positive sentiment\n",
      "\n",
      "['great', 'visual', 'plan', 'rotation']\n",
      "[[0.67092731]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'share', 'leggo']\n",
      "[[0.74420192]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'call', 'yolo']\n",
      "[[0.99899477]]\n",
      "Positive sentiment\n",
      "\n",
      "['call', 'contract', 'creates', 'best', 'chance', 'another', 'gamma', 'squeeze']\n",
      "[[0.88834043]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'fun', 'never', 'stop']\n",
      "[[0.33119575]]\n",
      "Negative sentiment\n",
      "\n",
      "['room', 'weak', 'hand', 'pltr']\n",
      "[[0.79813149]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'newbie', 'play']\n",
      "[[0.83412305]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'gain']\n",
      "[[0.82995472]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'loss', 'porn']\n",
      "[[0.1071787]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'yolo']\n",
      "[[0.99742721]]\n",
      "Positive sentiment\n",
      "\n",
      "['wsb', 'appreciation', 'post']\n",
      "[[0.47721214]]\n",
      "Negative sentiment\n",
      "\n",
      "['thank', 'rkt']\n",
      "[[0.68278821]]\n",
      "Positive sentiment\n",
      "\n",
      "['big', 'option', 'gain', 'thanks', 'rkt']\n",
      "[[0.93619873]]\n",
      "Positive sentiment\n",
      "\n",
      "['nice', 'rkt']\n",
      "[[0.66179433]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'prediction', 'march', 'huge', 'gain']\n",
      "[[0.93168915]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'please', 'read']\n",
      "[[0.56798563]]\n",
      "Positive sentiment\n",
      "\n",
      "['great', 'f', 'melvin']\n",
      "[[0.61687096]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'yolo']\n",
      "[[0.99906174]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'definitely', 'play']\n",
      "[[0.80107164]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'gain', 'porn']\n",
      "[[0.90427361]]\n",
      "Positive sentiment\n",
      "\n",
      "['loss', 'porn', 'fucked', 'gme', 'option']\n",
      "[[0.06618327]]\n",
      "Negative sentiment\n",
      "\n",
      "['unfi', 'yolo', 'march']\n",
      "[[0.99900951]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'gain', 'today']\n",
      "[[0.93835593]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'update', 'gain']\n",
      "[[0.97667856]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'greater', 'chance', 'gain', 'imo']\n",
      "[[0.94982538]]\n",
      "Positive sentiment\n",
      "\n",
      "['thanks', 'beautiful', 'bastard', 'child', 'rkt']\n",
      "[[0.75326482]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'gain']\n",
      "[[0.93058216]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo']\n",
      "[[0.9992454]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'gain', 'porn']\n",
      "[[0.90427361]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo', 'update']\n",
      "[[0.99975833]]\n",
      "Positive sentiment\n",
      "\n",
      "['law', 'abiding', 'retard']\n",
      "[[0.43888507]]\n",
      "Negative sentiment\n",
      "\n",
      "['little', 'rkt', 'gain', 'thank']\n",
      "[[0.94364435]]\n",
      "Positive sentiment\n",
      "\n",
      "['ape', 'together', 'strong', 'gme', 'yolo', 'update']\n",
      "[[0.99962864]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo']\n",
      "[[0.99742721]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo', 'share']\n",
      "[[0.99982649]]\n",
      "Positive sentiment\n",
      "\n",
      "['unfi', 'yolo', 'march']\n",
      "[[0.99900951]]\n",
      "Positive sentiment\n",
      "\n",
      "['loss', 'porn', 'rkt']\n",
      "[[0.24795874]]\n",
      "Negative sentiment\n",
      "\n",
      "['mod', 'please', 'explain']\n",
      "[[0.64121494]]\n",
      "Positive sentiment\n",
      "\n",
      "['first', 'gain', 'porn', 'rode', 'rkt', 'straight', 'top', 'gain']\n",
      "[[0.98955634]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'gain', 'straight', 'gme', 'share']\n",
      "[[0.97640315]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'uwmc', 'german', 'autist', 'late', 'party', 'holding', 'please', 'save', 'ape', 'friend']\n",
      "[[0.96280073]]\n",
      "Positive sentiment\n",
      "\n",
      "['thanks', 'rkt']\n",
      "[[0.72889339]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['mod', 'love', 'full', 'homo']\n",
      "[[0.62749427]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo']\n",
      "[[0.9992454]]\n",
      "Positive sentiment\n",
      "\n",
      "['nclh', 'yolo', 'update']\n",
      "[[0.9995006]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'yolo']\n",
      "[[0.99906174]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'yolo', 'update']\n",
      "[[0.99969947]]\n",
      "Positive sentiment\n",
      "\n",
      "['feeling', 'good', 'pltr', 'next', 'week']\n",
      "[[0.803894]]\n",
      "Positive sentiment\n",
      "\n",
      "['wti', 'crude', 'oil']\n",
      "[[0.47611857]]\n",
      "Negative sentiment\n",
      "\n",
      "['uwmc', 'yolo', 'update']\n",
      "[[0.99975833]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'failure', 'deliver']\n",
      "[[0.37481603]]\n",
      "Negative sentiment\n",
      "\n",
      "['yolo', 'uwmc', 'option', 'share']\n",
      "[[0.9998296]]\n",
      "Positive sentiment\n",
      "\n",
      "['poor', 'bb']\n",
      "[[0.46581563]]\n",
      "Negative sentiment\n",
      "\n",
      "['pltr', 'broke', 'heart']\n",
      "[[0.7297588]]\n",
      "Positive sentiment\n",
      "\n",
      "['fuck', 'cnbc', 'cramer', 'dis', 'track', 'reuploaded', 'cu', 'shit', 'bot']\n",
      "[[0.06554099]]\n",
      "Negative sentiment\n",
      "\n",
      "['yolo', 'uwmc']\n",
      "[[0.9992454]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'yolo']\n",
      "[[0.99906174]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo', 'share']\n",
      "[[0.99985656]]\n",
      "Positive sentiment\n",
      "\n",
      "['wti', 'yolo', 'update']\n",
      "[[0.99943806]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'uwmc', 'war']\n",
      "[[0.76645689]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo']\n",
      "[[0.99742721]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'holding', 'strong']\n",
      "[[0.82119655]]\n",
      "Positive sentiment\n",
      "\n",
      "['come', 'save', 'brother']\n",
      "[[0.6254426]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo']\n",
      "[[0.99742721]]\n",
      "Positive sentiment\n",
      "\n",
      "['love', 'see']\n",
      "[[0.6505486]]\n",
      "Positive sentiment\n",
      "\n",
      "['fnf', 'undervalued', 'oligopoly', 'play', 'good', 'option', 'value']\n",
      "[[0.76488382]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['unfi', 'deep', 'value', 'play', 'high', 'short', 'interest']\n",
      "[[0.87949162]]\n",
      "Positive sentiment\n",
      "\n",
      "['misleading', 'headlinedisappointing', 'dd']\n",
      "[[0.59298489]]\n",
      "Positive sentiment\n",
      "\n",
      "['update', 'unfi', 'yolo']\n",
      "[[0.99963648]]\n",
      "Positive sentiment\n",
      "\n",
      "['unfi', 'yolo', 'march']\n",
      "[[0.99900951]]\n",
      "Positive sentiment\n",
      "\n",
      "['true', 'retard', 'handle', 'gme', 'gain']\n",
      "[[0.83683764]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'update', 'unfi']\n",
      "[[0.99963648]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'still', 'holding', 'strong']\n",
      "[[0.82968031]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'amc']\n",
      "[[0.99880044]]\n",
      "Positive sentiment\n",
      "\n",
      "['small', 'gain', 'gain', 'r', 'gain']\n",
      "[[0.9976042]]\n",
      "Positive sentiment\n",
      "\n",
      "['lumn', 'yolo', 'update']\n",
      "[[0.99946785]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'rkt', 'share']\n",
      "[[0.99978423]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo', '’']\n",
      "[[0.99586067]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'rescue']\n",
      "[[0.40834025]]\n",
      "Negative sentiment\n",
      "\n",
      "['pltr', 'yolo', 'call']\n",
      "[[0.99947724]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo', 'update']\n",
      "[[0.999175]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'solid']\n",
      "[[0.59714485]]\n",
      "Positive sentiment\n",
      "\n",
      "['first', 'post', 'long', 'time', 'lurker', 'holding', 'strong', 'love']\n",
      "[[0.85382893]]\n",
      "Positive sentiment\n",
      "\n",
      "['retard', 'gme']\n",
      "[[0.36733814]]\n",
      "Negative sentiment\n",
      "\n",
      "['gme', 'goodness']\n",
      "[[0.40834025]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'yolo', 'update']\n",
      "[[0.99961571]]\n",
      "Positive sentiment\n",
      "\n",
      "['god', 'damn', 'moon', 'go', 'hopefully', 'call', 'print', 'well', 'lol']\n",
      "[[0.75489072]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo', 'update', 'thank', 'udfv', 'showing', 'true', 'value']\n",
      "[[0.99957649]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo']\n",
      "[[0.99742721]]\n",
      "Positive sentiment\n",
      "\n",
      "['snv', 'long', 'gain']\n",
      "[[0.89277121]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'stalling', 'despite', 'gme', 'gain']\n",
      "[[0.83620105]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'yolo', 'lfgggg']\n",
      "[[0.99857601]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo', 'part']\n",
      "[[0.99750747]]\n",
      "Positive sentiment\n",
      "\n",
      "['new', 'gme', 'gain', 'porn', 'love', 'stock']\n",
      "[[0.83488449]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'look', 'ready']\n",
      "[[0.63470151]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'share']\n",
      "[[0.88877453]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo', 'short', 'may', 'best', 'retard', 'win']\n",
      "[[0.99958962]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'briefly', 'thanks', 'afterhours', 'hero']\n",
      "[[0.51054798]]\n",
      "Positive sentiment\n",
      "\n",
      "['today', 'gme', 'manipulation']\n",
      "[[0.36631993]]\n",
      "Negative sentiment\n",
      "\n",
      "['pltr', 'rewarding', 'loyalty']\n",
      "[[0.74643243]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'life', 'damn', 'dirty', 'ape']\n",
      "[[0.36733814]]\n",
      "Negative sentiment\n",
      "\n",
      "['uwmc', 'yolo']\n",
      "[[0.9992454]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'gain']\n",
      "[[0.82995472]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'gain']\n",
      "[[0.82995472]]\n",
      "Positive sentiment\n",
      "\n",
      "['riot', 'gme', 'yolo']\n",
      "[[0.99713175]]\n",
      "Positive sentiment\n",
      "\n",
      "['nio', 'gain']\n",
      "[[0.89363344]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'leap']\n",
      "[[0.99849017]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'update', 'yolo']\n",
      "[[0.99975833]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'uwmc']\n",
      "[[0.9992454]]\n",
      "Positive sentiment\n",
      "\n",
      "['update', 'rkt', 'share']\n",
      "[[0.96148392]]\n",
      "Positive sentiment\n",
      "\n",
      "['share', 'rblx', 'yolo']\n",
      "[[0.99961791]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo', 'loss', 'peak', 'wed', 'give', 'positive', 'thought', 'please']\n",
      "[[0.99580157]]\n",
      "Positive sentiment\n",
      "\n",
      "['btd', 'nio', 'minute']\n",
      "[[0.50787121]]\n",
      "Positive sentiment\n",
      "\n",
      "['march', 'solid', 'info', 'thruster', 'engaged']\n",
      "[[0.55083342]]\n",
      "Positive sentiment\n",
      "\n",
      "['retarded', 'cv', 'dd']\n",
      "[[0.52592623]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo', 'update']\n",
      "[[0.999175]]\n",
      "Positive sentiment\n",
      "\n",
      "['diamond', 'fit', 'hand', 'bullish', 'diamond', 'gme']\n",
      "[[0.66216845]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo', 'update']\n",
      "[[0.999175]]\n",
      "Positive sentiment\n",
      "\n",
      "['unfi', 'yolo']\n",
      "[[0.99886523]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'gme']\n",
      "[[0.99742721]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'riot', 'yolo', 'update', 'march']\n",
      "[[0.99919706]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'fair', 'value']\n",
      "[[0.50260665]]\n",
      "Positive sentiment\n",
      "\n",
      "['tr', 'yolo']\n",
      "[[0.99833943]]\n",
      "Positive sentiment\n",
      "\n",
      "['nok', 'yolo', 'update']\n",
      "[[0.99936752]]\n",
      "Positive sentiment\n",
      "\n",
      "['round', 'rkt', 'loss']\n",
      "[[0.31578857]]\n",
      "Negative sentiment\n",
      "\n",
      "['please', 'help', 'calculate', 'fair', 'gme', 'price', 'postsqueeze']\n",
      "[[0.71465593]]\n",
      "Positive sentiment\n",
      "\n",
      "['dis', 'yolo']\n",
      "[[0.99824657]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'fake', 'news']\n",
      "[[0.57843346]]\n",
      "Positive sentiment\n",
      "\n",
      "['another', 'upwk', 'yolo', 'hope', 'always', 'best', 'investment', 'strategy']\n",
      "[[0.99966952]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'share']\n",
      "[[0.74420192]]\n",
      "Positive sentiment\n",
      "\n",
      "['fsr', 'worth', 'share']\n",
      "[[0.84097844]]\n",
      "Positive sentiment\n",
      "\n",
      "['update', 'gme', 'yolo', 'stop', 'loss', 'triggered', 'lesson', 'learnedno', 'stop', 'loss', 'set', 'ing']\n",
      "[[0.93498134]]\n",
      "Positive sentiment\n",
      "\n",
      "['gamestopped', 'bill', 'nasty']\n",
      "[[0.47611857]]\n",
      "Negative sentiment\n",
      "\n",
      "['uwmc', 'yolo']\n",
      "[[0.9992454]]\n",
      "Positive sentiment\n",
      "\n",
      "['ape', 'unite', 'cheap', 'profitable', 'russell', 'inclusion', 'dividend', 'short', 'interest', 'wow']\n",
      "[[0.78622958]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'cuz', 'like', 'stonk']\n",
      "[[0.99907879]]\n",
      "Positive sentiment\n",
      "\n",
      "['great', 'gme', 'squeeze']\n",
      "[[0.56798563]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'yolo']\n",
      "[[0.99906174]]\n",
      "Positive sentiment\n",
      "\n",
      "['lion', 'ape', 'could', 'best', 'friend']\n",
      "[[0.85273129]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'jumbo', 'prime', 'success', 'promising', 'start']\n",
      "[[0.69546066]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo']\n",
      "[[0.9992454]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo']\n",
      "[[0.9992454]]\n",
      "Positive sentiment\n",
      "\n",
      "['cry']\n",
      "[[0.42002915]]\n",
      "Negative sentiment\n",
      "\n",
      "['rkt', 'gain', 'share', 'bought']\n",
      "[[0.98539036]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo']\n",
      "[[0.9992454]]\n",
      "Positive sentiment\n",
      "\n",
      "['amrn', 'yolo', 'dd']\n",
      "[[0.9989728]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'crazy', 'bro']\n",
      "[[0.99808888]]\n",
      "Positive sentiment\n",
      "\n",
      "['dal', 'yolo']\n",
      "[[0.99833943]]\n",
      "Positive sentiment\n",
      "\n",
      "['unfi', 'yolo', 'march']\n",
      "[[0.99900951]]\n",
      "Positive sentiment\n",
      "\n",
      "['sure', 'yolo', 'loss', 'porn', 'well', 'see']\n",
      "[[0.99404094]]\n",
      "Positive sentiment\n",
      "\n",
      "['option', 'fun']\n",
      "[[0.5919264]]\n",
      "Positive sentiment\n",
      "\n",
      "['want', 'see', 'short', 'die', 'tomorrow', 'please', 'god', 'haha']\n",
      "[[0.76894733]]\n",
      "Positive sentiment\n",
      "\n",
      "['fsr', 'worth', 'share']\n",
      "[[0.84097844]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'analyst', 'rating', 'fud', 'bad', 'faith', 'abusing', 'analyst', 'position']\n",
      "[[0.5939117]]\n",
      "Positive sentiment\n",
      "\n",
      "['u', 'cannabis', 'yolo']\n",
      "[[0.99801759]]\n",
      "Positive sentiment\n",
      "\n",
      "['unfi', 'yolo', 'update']\n",
      "[[0.99963648]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'another', 'share']\n",
      "[[0.86311142]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['like', 'pltr', 'make', 'rich', 'please']\n",
      "[[0.91403716]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'technical', 'analysis']\n",
      "[[0.8278138]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'yolo', 'update']\n",
      "[[0.99961571]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'value', 'play', 'mx', 'magnachip', 'make', 'oled', 'semiconductor', 'upside', 'today', 'potential', 'gain']\n",
      "[[0.99234821]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'yolo']\n",
      "[[0.99906174]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'gain', '—', 'best', 'leap', 'imaginable']\n",
      "[[0.96367448]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo', 'share', 'im', 'allin']\n",
      "[[0.99978617]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'might', 'good', 'er', 'play']\n",
      "[[0.73062246]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'loss', 'porn']\n",
      "[[0.33155627]]\n",
      "Negative sentiment\n",
      "\n",
      "['unfi', 'yolo', 'march']\n",
      "[[0.99900951]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'amc', 'premarket']\n",
      "[[0.99883791]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'yolo', 'update']\n",
      "[[0.99961571]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'europoor', 'yolo']\n",
      "[[0.99750747]]\n",
      "Positive sentiment\n",
      "\n",
      "['diamond', 'handing', 'gme', 'share']\n",
      "[[0.80634743]]\n",
      "Positive sentiment\n",
      "\n",
      "['opportunity', 'gain', 'mx', 'bought']\n",
      "[[0.91442344]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo', 'update']\n",
      "[[0.99975833]]\n",
      "Positive sentiment\n",
      "\n",
      "['ok', 'ok', 'inflation', 'caused', 'small', 'trader', 'ok', 'well']\n",
      "[[0.58522882]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'yolo', 'update', 'share']\n",
      "[[0.99991166]]\n",
      "Positive sentiment\n",
      "\n",
      "['profit', 'tax', 'bill', 'lmao']\n",
      "[[0.57428435]]\n",
      "Positive sentiment\n",
      "\n",
      "['yoloing', 'gme', 'gain', 'rkt', 'great', 'company']\n",
      "[[0.9365756]]\n",
      "Positive sentiment\n",
      "\n",
      "['increase', 'yolo', 'rkt', 'month', 'pay', 'share']\n",
      "[[0.99980561]]\n",
      "Positive sentiment\n",
      "\n",
      "['calx', 'yolo']\n",
      "[[0.99833943]]\n",
      "Positive sentiment\n",
      "\n",
      "['calx', 'yolo', 'update']\n",
      "[[0.99946785]]\n",
      "Positive sentiment\n",
      "\n",
      "['psfe', 'yolo']\n",
      "[[0.99844151]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'amc']\n",
      "[[0.99880044]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo', 'happy', 'easter', 'boy']\n",
      "[[0.99755201]]\n",
      "Positive sentiment\n",
      "\n",
      "['youre', 'probably', 'playing', 'gme', 'wrong']\n",
      "[[0.33429633]]\n",
      "Negative sentiment\n",
      "\n",
      "['pltr', 'boomer', 'yolo']\n",
      "[[0.99939561]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'lost', 'porn', 'feeling', 'love']\n",
      "[[0.56508899]]\n",
      "Positive sentiment\n",
      "\n",
      "['could', 'fun']\n",
      "[[0.58974128]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'aso', 'retard', 'yolo', 'wish', 'luck']\n",
      "[[0.99874199]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo', 'apr']\n",
      "[[0.99929182]]\n",
      "Positive sentiment\n",
      "\n",
      "['interesting', 'amusing', 'news', 'nio']\n",
      "[[0.52940678]]\n",
      "Positive sentiment\n",
      "\n",
      "['pbf', 'energy', 'yolo']\n",
      "[[0.99859573]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo', 'continued']\n",
      "[[0.99750747]]\n",
      "Positive sentiment\n",
      "\n",
      "['rmo', 'yolo']\n",
      "[[0.99833943]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo', 'share', 'let', 'go']\n",
      "[[0.99945399]]\n",
      "Positive sentiment\n",
      "\n",
      "['fubo', 'please', 'make', 'rich']\n",
      "[[0.72168999]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'weekly', 'yolo', 'guy', 'please', 'give', 'confirmation', 'bias', 'feeling', 'pretty']\n",
      "[[0.99906331]]\n",
      "Positive sentiment\n",
      "\n",
      "['unfi', 'yolo', 'april']\n",
      "[[0.99890068]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'yolo', 'update']\n",
      "[[0.99952901]]\n",
      "Positive sentiment\n",
      "\n",
      "['mo', 'yolo', 'update']\n",
      "[[0.99948448]]\n",
      "Positive sentiment\n",
      "\n",
      "['well', 'shiiiii—']\n",
      "[[0.62428785]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'share']\n",
      "[[0.74420192]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'termonal', 'drop']\n",
      "[[0.34964071]]\n",
      "Negative sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'currently', 'profit', 'gfb', 'happy', 'gme']\n",
      "[[0.99812618]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo', 'update']\n",
      "[[0.999175]]\n",
      "Positive sentiment\n",
      "\n",
      "['tesla', 'yolo', 'leap', 'faith']\n",
      "[[0.99850374]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'ttcf', 'leap']\n",
      "[[0.99853732]]\n",
      "Positive sentiment\n",
      "\n",
      "['fubo', 'yolo']\n",
      "[[0.99849017]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', '’', 'ed', 'everything', 'gme', 'like', 'true', 'retard']\n",
      "[[0.99781208]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'demo', 'yolo']\n",
      "[[0.99939561]]\n",
      "Positive sentiment\n",
      "\n",
      "['viac', 'yolo', 'join', 'fun', 'homies']\n",
      "[[0.99890068]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo', 'update']\n",
      "[[0.999175]]\n",
      "Positive sentiment\n",
      "\n",
      "['fsr', 'yolo', 'update']\n",
      "[[0.9995006]]\n",
      "Positive sentiment\n",
      "\n",
      "['luck', 'sklz']\n",
      "[[0.59522993]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'uwmc']\n",
      "[[0.9992454]]\n",
      "Positive sentiment\n",
      "\n",
      "['rblx', 'weekly', 'yolo']\n",
      "[[0.99844151]]\n",
      "Positive sentiment\n",
      "\n",
      "['clov', 'dd', 'bullshit']\n",
      "[[0.65569869]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'fb']\n",
      "[[0.99844151]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'yolo', 'update', 'ape', 'love', 'movie']\n",
      "[[0.99982308]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'yolo']\n",
      "[[0.9985301]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo']\n",
      "[[0.9992454]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['love', 'pltr', 'love']\n",
      "[[0.90151191]]\n",
      "Positive sentiment\n",
      "\n",
      "['low', 'stress', 'shitput', 'gain', 'mostly', 'gme']\n",
      "[[0.81537734]]\n",
      "Positive sentiment\n",
      "\n",
      "['vmw', 'yolo', 'update']\n",
      "[[0.99946785]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'amc']\n",
      "[[0.99880044]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'yolo', 'call', 'gone', 'wrong']\n",
      "[[0.99860646]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo']\n",
      "[[0.99742721]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'call', 'yolo']\n",
      "[[0.99921378]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo', 'update']\n",
      "[[0.99980021]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo', 'portfolio', 'pl', 'risk', 'level', 'safe']\n",
      "[[0.99762838]]\n",
      "Positive sentiment\n",
      "\n",
      "['low', 'risk', 'high', 'reward']\n",
      "[[0.48740158]]\n",
      "Negative sentiment\n",
      "\n",
      "['baba', 'yolo']\n",
      "[[0.99853732]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo', 'sold', 'share', 'buy']\n",
      "[[0.99987648]]\n",
      "Positive sentiment\n",
      "\n",
      "['like', 'nok']\n",
      "[[0.5962204]]\n",
      "Positive sentiment\n",
      "\n",
      "['wsb', 'love', 'gain', 'loss', 'yolo', 'post', 'rule', 'review']\n",
      "[[0.99941643]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo', 'like', 'stock']\n",
      "[[0.99958701]]\n",
      "Positive sentiment\n",
      "\n",
      "['win', 'shame', 'sold', 'bit', 'early', 'haha']\n",
      "[[0.52373973]]\n",
      "Positive sentiment\n",
      "\n",
      "['jnj', 'yolo']\n",
      "[[0.99828592]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'vmw']\n",
      "[[0.99833943]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'yolo', 'weekly', 'update', 'share']\n",
      "[[0.9999171]]\n",
      "Positive sentiment\n",
      "\n",
      "['moderate', 'gain', 'baba']\n",
      "[[0.89870416]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo', 'update']\n",
      "[[0.99975833]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo', 'apr']\n",
      "[[0.99929182]]\n",
      "Positive sentiment\n",
      "\n",
      "['gnw', 'profit', 'overnight']\n",
      "[[0.56427803]]\n",
      "Positive sentiment\n",
      "\n",
      "['aapl', 'best']\n",
      "[[0.81856701]]\n",
      "Positive sentiment\n",
      "\n",
      "['nclh', 'yolo']\n",
      "[[0.99844151]]\n",
      "Positive sentiment\n",
      "\n",
      "['nok', 'super', 'undervalued']\n",
      "[[0.53159053]]\n",
      "Positive sentiment\n",
      "\n",
      "['fb', 'gain']\n",
      "[[0.88969153]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'yolo']\n",
      "[[0.9985301]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'sklz']\n",
      "[[0.99844151]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltrard', 'yolo', 'wish', 'luck', 'fam']\n",
      "[[0.9992489]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'sklz']\n",
      "[[0.99844151]]\n",
      "Positive sentiment\n",
      "\n",
      "['hope', 'please', 'help', 'nio']\n",
      "[[0.78238399]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo', 'apr']\n",
      "[[0.99929182]]\n",
      "Positive sentiment\n",
      "\n",
      "['fsr', 'yolo']\n",
      "[[0.99844151]]\n",
      "Positive sentiment\n",
      "\n",
      "['sklz', 'yolo', 'update']\n",
      "[[0.9995006]]\n",
      "Positive sentiment\n",
      "\n",
      "['please', 'save', 'cathie']\n",
      "[[0.74304742]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'loss', 'porn', 'bonus', 'loss', 'porn', 'f']\n",
      "[[0.05470469]]\n",
      "Negative sentiment\n",
      "\n",
      "['realized', 'nue', 'gain']\n",
      "[[0.87509887]]\n",
      "Positive sentiment\n",
      "\n",
      "['jmia', 'contract', 'yolo']\n",
      "[[0.99853732]]\n",
      "Positive sentiment\n",
      "\n",
      "['viac', 'war', 'cry']\n",
      "[[0.37013647]]\n",
      "Negative sentiment\n",
      "\n",
      "['rkt', 'loss', 'porn']\n",
      "[[0.24795874]]\n",
      "Negative sentiment\n",
      "\n",
      "['uwmc', 'buying', 'opportunity']\n",
      "[[0.72889339]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'fomo', 'gone', 'wrong']\n",
      "[[0.55631723]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'yolo', 'share', 'earnings', 'thursday', 'boost', 'awesome', 'gain']\n",
      "[[0.99997599]]\n",
      "Positive sentiment\n",
      "\n",
      "['full', 'yolo', 'low', 'risk', 'high', 'reward', 'mo', 'play', 'one', 'cared']\n",
      "[[0.99905298]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'nclh']\n",
      "[[0.99844151]]\n",
      "Positive sentiment\n",
      "\n",
      "['baba', 'loss', 'porn']\n",
      "[[0.17450091]]\n",
      "Negative sentiment\n",
      "\n",
      "['rkt', 'loss', 'porn', 'enjoy']\n",
      "[[0.25393066]]\n",
      "Negative sentiment\n",
      "\n",
      "['valued', 'msft', 'surprisingly', 'well']\n",
      "[[0.63907029]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'dont', 'fooled', 'friend']\n",
      "[[0.72981227]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'yolo', 'update', 'ohhhmy', 'sore']\n",
      "[[0.99966487]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'friend', 'gme', 'hold', 'hold', 'hold']\n",
      "[[0.99671308]]\n",
      "Positive sentiment\n",
      "\n",
      "['mt', 'possible', 'value', 'play']\n",
      "[[0.69737165]]\n",
      "Positive sentiment\n",
      "\n",
      "['jmia', 'earnings', 'yolo']\n",
      "[[0.99883917]]\n",
      "Positive sentiment\n",
      "\n",
      "['love', 'pltr']\n",
      "[[0.83412305]]\n",
      "Positive sentiment\n",
      "\n",
      "['save', 'u', 'janet', 'yellen']\n",
      "[[0.5830331]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'great', 'investment', 'bought', 'share', 'second', 'account', 'share', 'total', 'life', 'great']\n",
      "[[0.97850229]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo', 'still', 'stupid']\n",
      "[[0.99930735]]\n",
      "Positive sentiment\n",
      "\n",
      "['ag', 'yolo']\n",
      "[[0.99844151]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo', 'btfd', 'ignore', 'hedge', 'like', 'retarded']\n",
      "[[0.99931057]]\n",
      "Positive sentiment\n",
      "\n",
      "['honestly', '’', 'wrong', 'ge']\n",
      "[[0.31691262]]\n",
      "Negative sentiment\n",
      "\n",
      "['fdx', 'yolo']\n",
      "[[0.99833943]]\n",
      "Positive sentiment\n",
      "\n",
      "['wwe', 'stone', 'cold', 'stunning', 'opportunity']\n",
      "[[0.58203296]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'uwmc']\n",
      "[[0.9992454]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo']\n",
      "[[0.9992454]]\n",
      "Positive sentiment\n",
      "\n",
      "['ag', 'yolo']\n",
      "[[0.99844151]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['deep', 'value', 'biotech', 'play', 'myov']\n",
      "[[0.74042419]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'hate', 'money']\n",
      "[[0.7161007]]\n",
      "Positive sentiment\n",
      "\n",
      "['love', 'wsb', 'pltr']\n",
      "[[0.83536991]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'red', 'devil']\n",
      "[[0.69633099]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'chip', 'shortage', 'buyin']\n",
      "[[0.8278138]]\n",
      "Positive sentiment\n",
      "\n",
      "['cat', 'dont', 'care']\n",
      "[[0.49198681]]\n",
      "Negative sentiment\n",
      "\n",
      "['cleveland', 'cliff', 'clf', 'commodity', 'super', 'cycle', 'play']\n",
      "[[0.72981227]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo', 'fucked']\n",
      "[[0.99892449]]\n",
      "Positive sentiment\n",
      "\n",
      "['today', 'fun', 'tomorrow', 'gon', 'na', 'amazing']\n",
      "[[0.62755766]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo', '’', 'kinda', 'dumb']\n",
      "[[0.99881674]]\n",
      "Positive sentiment\n",
      "\n",
      "['someone', 'pls', 'save']\n",
      "[[0.64020578]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'yolo']\n",
      "[[0.99880044]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'gain', 'porn']\n",
      "[[0.88076467]]\n",
      "Positive sentiment\n",
      "\n",
      "['retarded', 'yolo', 'rgr']\n",
      "[[0.99749168]]\n",
      "Positive sentiment\n",
      "\n",
      "['spce', 'gain']\n",
      "[[0.89363344]]\n",
      "Positive sentiment\n",
      "\n",
      "['successful', 'retard', 'yolo', 'pltr']\n",
      "[[0.99930412]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'gain']\n",
      "[[0.89531417]]\n",
      "Positive sentiment\n",
      "\n",
      "['tsp', 'best', 'way', 'play', 'selfdriving', 'today']\n",
      "[[0.90857019]]\n",
      "Positive sentiment\n",
      "\n",
      "['loss', 'gme']\n",
      "[[0.1455597]]\n",
      "Negative sentiment\n",
      "\n",
      "['yolo', 'amc', 'call']\n",
      "[[0.99899477]]\n",
      "Positive sentiment\n",
      "\n",
      "['vertex', 'energy', 'dd']\n",
      "[[0.6648525]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'yolo']\n",
      "[[0.9985301]]\n",
      "Positive sentiment\n",
      "\n",
      "['spce', 'gain']\n",
      "[[0.89363344]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'thank', 'dear', 'retard']\n",
      "[[0.62403339]]\n",
      "Positive sentiment\n",
      "\n",
      "['tomorrow', 'fun']\n",
      "[[0.59522993]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'yolo', 'may']\n",
      "[[0.99926898]]\n",
      "Positive sentiment\n",
      "\n",
      "['spce', 'gain']\n",
      "[[0.89363344]]\n",
      "Positive sentiment\n",
      "\n",
      "['gain', 'spce']\n",
      "[[0.89363344]]\n",
      "Positive sentiment\n",
      "\n",
      "['war', 'profiteering', 'common', 'man']\n",
      "[[0.39805298]]\n",
      "Negative sentiment\n",
      "\n",
      "['well', 'miss']\n",
      "[[0.61680686]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'yolo', 'update']\n",
      "[[0.99961571]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'yolo', 'average']\n",
      "[[0.99883791]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'share', 'wish', 'u', 'luck']\n",
      "[[0.92502666]]\n",
      "Positive sentiment\n",
      "\n",
      "['well', 'well', 'well', 'turn', 'table']\n",
      "[[0.81500289]]\n",
      "Positive sentiment\n",
      "\n",
      "['proud', 'amc', 'retard', 'yolo']\n",
      "[[0.99866211]]\n",
      "Positive sentiment\n",
      "\n",
      "['zyme', 'yolo']\n",
      "[[0.99833943]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'baba', 'ko']\n",
      "[[0.99862724]]\n",
      "Positive sentiment\n",
      "\n",
      "['spce', 'yolo']\n",
      "[[0.99850374]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'baba', 'call']\n",
      "[[0.99877422]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'gain']\n",
      "[[0.95275633]]\n",
      "Positive sentiment\n",
      "\n",
      "['nio', 'yolo']\n",
      "[[0.99850374]]\n",
      "Positive sentiment\n",
      "\n",
      "['baba', 'yolo']\n",
      "[[0.99853732]]\n",
      "Positive sentiment\n",
      "\n",
      "['dd', 'uberpostmates', 'disaster']\n",
      "[[0.57976639]]\n",
      "Positive sentiment\n",
      "\n",
      "['spce', 'yolo', 'may']\n",
      "[[0.99855046]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'call', 'exciting']\n",
      "[[0.63888261]]\n",
      "Positive sentiment\n",
      "\n",
      "['ag', 'yolo']\n",
      "[[0.99844151]]\n",
      "Positive sentiment\n",
      "\n",
      "['fubo', 'amazing', 'quarter', 'result']\n",
      "[[0.53281697]]\n",
      "Positive sentiment\n",
      "\n",
      "['clf', 'yolo', 'love', 'steel', 'maker']\n",
      "[[0.99931395]]\n",
      "Positive sentiment\n",
      "\n",
      "['save', 'lordstown', 'motor', 'ride']\n",
      "[[0.61258954]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'locked', 'loaded', 'ready', 'ready', 'gain', 'next', 'week']\n",
      "[[0.93144425]]\n",
      "Positive sentiment\n",
      "\n",
      "['wish', 'worth', 'share', 'yolo', 'cc', 'protection', 'lol']\n",
      "[[0.99979291]]\n",
      "Positive sentiment\n",
      "\n",
      "['clov', 'v', 'well']\n",
      "[[0.688632]]\n",
      "Positive sentiment\n",
      "\n",
      "['foa', 'free', 'falling']\n",
      "[[0.58203296]]\n",
      "Positive sentiment\n",
      "\n",
      "['x', 'rated', 'gain', 'porn']\n",
      "[[0.84628997]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo', 'update']\n",
      "[[0.99980021]]\n",
      "Positive sentiment\n",
      "\n",
      "['cat', 'safe', 'profit', 'infrastructure', 'billundervalued']\n",
      "[[0.56649908]]\n",
      "Positive sentiment\n",
      "\n",
      "['well', 'v', 'clov']\n",
      "[[0.688632]]\n",
      "Positive sentiment\n",
      "\n",
      "['nio', 'yolo']\n",
      "[[0.99850374]]\n",
      "Positive sentiment\n",
      "\n",
      "['clf', 'yolo']\n",
      "[[0.99862724]]\n",
      "Positive sentiment\n",
      "\n",
      "['real', 'deep', 'value', 'play', 'dis']\n",
      "[[0.72350183]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'loss', 'porn']\n",
      "[[0.20497667]]\n",
      "Negative sentiment\n",
      "\n",
      "['ya', 'winning', 'son']\n",
      "[[0.56427803]]\n",
      "Positive sentiment\n",
      "\n",
      "['well']\n",
      "[[0.61680686]]\n",
      "Positive sentiment\n",
      "\n",
      "['clf', 'share', 'aboard', 'ready', 'lift']\n",
      "[[0.86851893]]\n",
      "Positive sentiment\n",
      "\n",
      "['rolled', 'amc', 'clov', 'gain', 'uwmc', 'wish', 'yolo']\n",
      "[[0.99996403]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'option', 'loss']\n",
      "[[0.27143204]]\n",
      "Negative sentiment\n",
      "\n",
      "['uwmc', 'yolo']\n",
      "[[0.9992454]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['wish', 'personal', 'dd', 'fair', 'price', 'share', 'target']\n",
      "[[0.93810187]]\n",
      "Positive sentiment\n",
      "\n",
      "['fb', 'gain']\n",
      "[[0.88969153]]\n",
      "Positive sentiment\n",
      "\n",
      "['umc', 'united', 'microelectronics']\n",
      "[[0.50903462]]\n",
      "Positive sentiment\n",
      "\n",
      "['thank', 'bb']\n",
      "[[0.57863184]]\n",
      "Positive sentiment\n",
      "\n",
      "['star', 'constructive', 'feedback', 'appreciated']\n",
      "[[0.53281697]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'gain']\n",
      "[[0.94341076]]\n",
      "Positive sentiment\n",
      "\n",
      "['clf', 'yolo', 'like', 'steel']\n",
      "[[0.99923855]]\n",
      "Positive sentiment\n",
      "\n",
      "['heavily', 'shorted', 'clean', 'air', 'smart', 'tech', 'company']\n",
      "[[0.53956046]]\n",
      "Positive sentiment\n",
      "\n",
      "['clf', 'yolo']\n",
      "[[0.99862724]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'wwe']\n",
      "[[0.99839128]]\n",
      "Positive sentiment\n",
      "\n",
      "['arvl', 'ta', 'strong', 'uptrend', 'nice', 'breakout', 'great', 'chart', 'setup']\n",
      "[[0.81033137]]\n",
      "Positive sentiment\n",
      "\n",
      "['clean', 'energy', 'reveals', 'plan', 'develop', 'natural', 'gas', 'dairy', 'share', 'roar']\n",
      "[[0.88969153]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'yolo']\n",
      "[[0.99880044]]\n",
      "Positive sentiment\n",
      "\n",
      "['well', 'wlyyf', 'well', 'health', 'look', 'ready', 'rocket']\n",
      "[[0.77444907]]\n",
      "Positive sentiment\n",
      "\n",
      "['f', 'l']\n",
      "[[0.51129339]]\n",
      "Positive sentiment\n",
      "\n",
      "['share', 'bb', 'best', 'breed']\n",
      "[[0.95815858]]\n",
      "Positive sentiment\n",
      "\n",
      "['wow']\n",
      "[[0.58203296]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['still', 'best', 'play', 'ever']\n",
      "[[0.90274491]]\n",
      "Positive sentiment\n",
      "\n",
      "['bgs', 'yolo', 'update']\n",
      "[[0.99946785]]\n",
      "Positive sentiment\n",
      "\n",
      "['et', 'value', 'play']\n",
      "[[0.70874923]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'round', 'thanks', 'jp']\n",
      "[[0.72163552]]\n",
      "Positive sentiment\n",
      "\n",
      "['itub', 'honest', 'unbiased', 'dd']\n",
      "[[0.6505486]]\n",
      "Positive sentiment\n",
      "\n",
      "['clf', 'yolo', 'send', 'help']\n",
      "[[0.99920686]]\n",
      "Positive sentiment\n",
      "\n",
      "['clf', 'strong', 'uptrend', 'great', 'setup', 'optimal', 'entry', 'point']\n",
      "[[0.80540006]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'lev']\n",
      "[[0.99833943]]\n",
      "Positive sentiment\n",
      "\n",
      "['ty', 'jpowell', 'didnt', 'disappoint']\n",
      "[[0.51922869]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'gme']\n",
      "[[0.99742721]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'retard', 'forever', 'loading']\n",
      "[[0.5043127]]\n",
      "Positive sentiment\n",
      "\n",
      "['itub', 'c', 'yolo']\n",
      "[[0.99845551]]\n",
      "Positive sentiment\n",
      "\n",
      "['fuck', 'itub', 'yolo']\n",
      "[[0.98840849]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'amc']\n",
      "[[0.99880044]]\n",
      "Positive sentiment\n",
      "\n",
      "['wish', 'v', 'uwmc', 'like', 'money']\n",
      "[[0.89100196]]\n",
      "Positive sentiment\n",
      "\n",
      "['wish', 'new', 'catalyst']\n",
      "[[0.61687096]]\n",
      "Positive sentiment\n",
      "\n",
      "['f', 'loss', 'found', 'road', 'dead']\n",
      "[[0.12667746]]\n",
      "Negative sentiment\n",
      "\n",
      "['rkt', 'uwmc', 'fud']\n",
      "[[0.77999694]]\n",
      "Positive sentiment\n",
      "\n",
      "['dd', 'yolo', 'freedom', 'foodstamps', 'mega', 'meme']\n",
      "[[0.99909528]]\n",
      "Positive sentiment\n",
      "\n",
      "['wish', 'c']\n",
      "[[0.65470833]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'allin', 'share', 'yolo', 'update']\n",
      "[[0.99995552]]\n",
      "Positive sentiment\n",
      "\n",
      "['transocean', 'rig', 'energy', 'stock', 'short', 'interest', 'update']\n",
      "[[0.85440895]]\n",
      "Positive sentiment\n",
      "\n",
      "['bet', 'resolve', 'amc', 'good', 'luck']\n",
      "[[0.72147206]]\n",
      "Positive sentiment\n",
      "\n",
      "['update', 'pltr', 'gain']\n",
      "[[0.98437537]]\n",
      "Positive sentiment\n",
      "\n",
      "['gld', 'yolo']\n",
      "[[0.99833943]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'hope', 'bb', 'hit']\n",
      "[[0.9985564]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo', 'holding', 'strong']\n",
      "[[0.99975046]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'ticker', 'yep', 'called', 'best']\n",
      "[[0.95438098]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'yolo']\n",
      "[[0.9985301]]\n",
      "Positive sentiment\n",
      "\n",
      "['pain', 'bros', 'pain']\n",
      "[[0.44117909]]\n",
      "Negative sentiment\n",
      "\n",
      "['mini', 'retard', 'yolo', 'pltr']\n",
      "[[0.99924147]]\n",
      "Positive sentiment\n",
      "\n",
      "['baba', 'call', 'gain']\n",
      "[[0.91117542]]\n",
      "Positive sentiment\n",
      "\n",
      "['nok', 'looking', 'strong']\n",
      "[[0.66783673]]\n",
      "Positive sentiment\n",
      "\n",
      "['thanks', 'spce']\n",
      "[[0.62755766]]\n",
      "Positive sentiment\n",
      "\n",
      "['psfe', 'gain', 'porn', 'first', 'gain', 'porn', 'post']\n",
      "[[0.96763907]]\n",
      "Positive sentiment\n",
      "\n",
      "['psfe', 'yolo']\n",
      "[[0.99844151]]\n",
      "Positive sentiment\n",
      "\n",
      "['psfe', 'yolo', 'beautiful', 'company']\n",
      "[[0.99846938]]\n",
      "Positive sentiment\n",
      "\n",
      "['baba', 'yolo', 'increased', 'position']\n",
      "[[0.99863958]]\n",
      "Positive sentiment\n",
      "\n",
      "['wish', 'option', 'ramp']\n",
      "[[0.64435919]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'true', 'yolo', 'everything']\n",
      "[[0.99939578]]\n",
      "Positive sentiment\n",
      "\n",
      "['gnrc', 'yolo', 'update']\n",
      "[[0.99948448]]\n",
      "Positive sentiment\n",
      "\n",
      "['share', 'yolo', 'kbh', 'expecting', 'positive', 'earnings', 'today', 'lfg']\n",
      "[[0.99979662]]\n",
      "Positive sentiment\n",
      "\n",
      "['wish', 'v', 'amazon']\n",
      "[[0.68284694]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'strong']\n",
      "[[0.8360091]]\n",
      "Positive sentiment\n",
      "\n",
      "['wish', 'moon', 'wich', 'u', 'luck']\n",
      "[[0.68568824]]\n",
      "Positive sentiment\n",
      "\n",
      "['kbh', 'place', 'like', 'homo']\n",
      "[[0.61362941]]\n",
      "Positive sentiment\n",
      "\n",
      "['gme', 'yolo']\n",
      "[[0.99742721]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', '’', 'amc', 'profit', 'wish', 'today', 'wish', 'luck', 'ape']\n",
      "[[0.99968935]]\n",
      "Positive sentiment\n",
      "\n",
      "['x', 'great', 'return']\n",
      "[[0.63495298]]\n",
      "Positive sentiment\n",
      "\n",
      "['wish', 'pretty', 'much', 'sure', 'thing', 'ecommerce', 'pro', 'opinion']\n",
      "[[0.64955135]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'amc']\n",
      "[[0.99880044]]\n",
      "Positive sentiment\n",
      "\n",
      "['still', 'alive', 'back', 'wish']\n",
      "[[0.65464702]]\n",
      "Positive sentiment\n",
      "\n",
      "['wish', 'v', 'clov', 'chose', 'wish']\n",
      "[[0.80753733]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'gme']\n",
      "[[0.99742721]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'wish', 'luck']\n",
      "[[0.76635979]]\n",
      "Positive sentiment\n",
      "\n",
      "['clf', 'yolo']\n",
      "[[0.99862724]]\n",
      "Positive sentiment\n",
      "\n",
      "['body', 'yolo']\n",
      "[[0.99814853]]\n",
      "Positive sentiment\n",
      "\n",
      "['c', 'amd', 'gain']\n",
      "[[0.89277121]]\n",
      "Positive sentiment\n",
      "\n",
      "['nio', 'put', 'yolo']\n",
      "[[0.99855046]]\n",
      "Positive sentiment\n",
      "\n",
      "['wish', 'dd']\n",
      "[[0.73603124]]\n",
      "Positive sentiment\n",
      "\n",
      "['best', 'palantir', 'analysis', 'around']\n",
      "[[0.83668335]]\n",
      "Positive sentiment\n",
      "\n",
      "['vsto', 'gain']\n",
      "[[0.88653465]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['baba', 'yolo']\n",
      "[[0.99853732]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'bagholders', 'rejoice']\n",
      "[[0.73421844]]\n",
      "Positive sentiment\n",
      "\n",
      "['like', 'kbh']\n",
      "[[0.63177309]]\n",
      "Positive sentiment\n",
      "\n",
      "['bark', 'position', 'love', 'bitch']\n",
      "[[0.60711625]]\n",
      "Positive sentiment\n",
      "\n",
      "['want', 'god', 'damn', 'real', 'gme', 'share']\n",
      "[[0.80277296]]\n",
      "Positive sentiment\n",
      "\n",
      "['lazy', 'post']\n",
      "[[0.46138764]]\n",
      "Negative sentiment\n",
      "\n",
      "['amc', 'fd', '’', 'yolo']\n",
      "[[0.99812872]]\n",
      "Positive sentiment\n",
      "\n",
      "['spce', 'yolo']\n",
      "[[0.99850374]]\n",
      "Positive sentiment\n",
      "\n",
      "['baba', 'yolo', 'update']\n",
      "[[0.99953133]]\n",
      "Positive sentiment\n",
      "\n",
      "['ge', 'yolo']\n",
      "[[0.99824657]]\n",
      "Positive sentiment\n",
      "\n",
      "['wkhs', 'looking', 'fun']\n",
      "[[0.64749103]]\n",
      "Positive sentiment\n",
      "\n",
      "['well', 'isnt', 'lovely', 'wish', 'loss', 'porn']\n",
      "[[0.33863496]]\n",
      "Negative sentiment\n",
      "\n",
      "['tellurian', 'nasdaq', 'tell', 'well', 'holding', 'growth', 'hopefully']\n",
      "[[0.73153764]]\n",
      "Positive sentiment\n",
      "\n",
      "['baba', 'yolo']\n",
      "[[0.99853732]]\n",
      "Positive sentiment\n",
      "\n",
      "['gnrc', 'yolo']\n",
      "[[0.99839128]]\n",
      "Positive sentiment\n",
      "\n",
      "['didi', 'yolo', 'broke', 'chinese', 'stock', 'rule']\n",
      "[[0.99755862]]\n",
      "Positive sentiment\n",
      "\n",
      "['looking', 'best', 'gold', 'play']\n",
      "[[0.90194843]]\n",
      "Positive sentiment\n",
      "\n",
      "['bb', 'yolo', 'update']\n",
      "[[0.99952901]]\n",
      "Positive sentiment\n",
      "\n",
      "['body', 'loss', 'porn']\n",
      "[[0.14305405]]\n",
      "Negative sentiment\n",
      "\n",
      "['oil', 'dd', 'modest', 'yolo', 'opportunity']\n",
      "[[0.99911147]]\n",
      "Positive sentiment\n",
      "\n",
      "['expanding', 'market', 'share', 'superior', 'product', 'share', 'buy', 'back', 'sigh']\n",
      "[[0.9545597]]\n",
      "Positive sentiment\n",
      "\n",
      "['avepoint', 'dd', 'yolo']\n",
      "[[0.9989728]]\n",
      "Positive sentiment\n",
      "\n",
      "['snap', 'earnings', 'play']\n",
      "[[0.71710113]]\n",
      "Positive sentiment\n",
      "\n",
      "['well', 'fargo', 'ceasing', 'credit', 'line']\n",
      "[[0.62428785]]\n",
      "Positive sentiment\n",
      "\n",
      "['wish', 'diamond', 'hand', 'dd', 'still', 'buy']\n",
      "[[0.87455944]]\n",
      "Positive sentiment\n",
      "\n",
      "['ko', 'kosmos', 'energy']\n",
      "[[0.56649908]]\n",
      "Positive sentiment\n",
      "\n",
      "['spce', 'like', 'everyone', 'im', 'yolo', 'play', 'full', 'size', 'account', 'wish', 'luck', 'bagholders']\n",
      "[[0.99974241]]\n",
      "Positive sentiment\n",
      "\n",
      "['xom', 'yolo']\n",
      "[[0.99828592]]\n",
      "Positive sentiment\n",
      "\n",
      "['rkt', 'yolo', 'put', 'credit', 'spread', 'addict']\n",
      "[[0.99911946]]\n",
      "Positive sentiment\n",
      "\n",
      "['stock', 'war', 'gay', 'bear', 'strike', 'back']\n",
      "[[0.36796861]]\n",
      "Negative sentiment\n",
      "\n",
      "['lost', 'spce']\n",
      "[[0.48856466]]\n",
      "Negative sentiment\n",
      "\n",
      "['baba', 'yolo']\n",
      "[[0.99853732]]\n",
      "Positive sentiment\n",
      "\n",
      "['share', 'amc']\n",
      "[[0.86203997]]\n",
      "Positive sentiment\n",
      "\n",
      "['’', 'best', 'play', 'assuming', 'catastrophic', 'climate', 'shift']\n",
      "[[0.84450017]]\n",
      "Positive sentiment\n",
      "\n",
      "['amc', 'yolo', 'gain', 'position', 'selling', 'premium']\n",
      "[[0.99978299]]\n",
      "Positive sentiment\n",
      "\n",
      "['ggb', 'huge', 'potential']\n",
      "[[0.54071672]]\n",
      "Positive sentiment\n",
      "\n",
      "['january', 'could', 'fun']\n",
      "[[0.58974128]]\n",
      "Positive sentiment\n",
      "\n",
      "['lac', 'yolo']\n",
      "[[0.99844151]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'psfe']\n",
      "[[0.99844151]]\n",
      "Positive sentiment\n",
      "\n",
      "['nio', 'loss', 'porn', 'got', 'screwed', 'didi', 'fiasco']\n",
      "[[0.15335426]]\n",
      "Negative sentiment\n",
      "\n",
      "['clf', 'yolo']\n",
      "[[0.99862724]]\n",
      "Positive sentiment\n",
      "\n",
      "['mighty', 'god', 'please', 'save', 'amen', 'send', 'amc', 'heavenly', 'grace', 'lord', 'god', 'save', 'ugly', 'lord', 'god', 'get', 'rid', 'wife', '’', 'boyfriend', 'lord', 'god', 'amen']\n",
      "[[0.95846551]]\n",
      "Positive sentiment\n",
      "\n",
      "['sndl', 'yolo', 'play', 'pay']\n",
      "[[0.99895865]]\n",
      "Positive sentiment\n",
      "\n",
      "['contract', 'yolo', 'spce']\n",
      "[[0.99863958]]\n",
      "Positive sentiment\n",
      "\n",
      "['clf', 'yolo']\n",
      "[[0.99862724]]\n",
      "Positive sentiment\n",
      "\n",
      "['thank', 'playing', 'please', 'come', 'back', 'soon']\n",
      "[[0.70778739]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'earnings', 'cheat', 'code']\n",
      "[[0.73952852]]\n",
      "Positive sentiment\n",
      "\n",
      "['cpng', 'yolo']\n",
      "[[0.99833943]]\n",
      "Positive sentiment\n",
      "\n",
      "['uwmc', 'earnings', 'yolo']\n",
      "[[0.99945562]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'fubo']\n",
      "[[0.99849017]]\n",
      "Positive sentiment\n",
      "\n",
      "['dis', 'tiny', 'yolo']\n",
      "[[0.99830131]]\n",
      "Positive sentiment\n",
      "\n",
      "['big', 'lost']\n",
      "[[0.37970016]]\n",
      "Negative sentiment\n",
      "\n",
      "['wtf', 'pltr', 'retard', 'edition']\n",
      "[[0.64102775]]\n",
      "Positive sentiment\n",
      "\n",
      "['help', 'bought', 'wish', 'fds']\n",
      "[[0.76977334]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'fubo']\n",
      "[[0.99849017]]\n",
      "Positive sentiment\n",
      "\n",
      "['pubm', 'yolo', 'low', 'float', 'high', 'si', 'great', 'earnings']\n",
      "[[0.99931695]]\n",
      "Positive sentiment\n",
      "\n",
      "['pubm', 'pubmatic', 'simple', 'safe', 'play']\n",
      "[[0.68869014]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'lac']\n",
      "[[0.99844151]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['sweet', 'gain', 'lac']\n",
      "[[0.89277121]]\n",
      "Positive sentiment\n",
      "\n",
      "['save', 'portfolio']\n",
      "[[0.61044224]]\n",
      "Positive sentiment\n",
      "\n",
      "['super', 'wallstreet', 'bros', 'bet']\n",
      "[[0.54180521]]\n",
      "Positive sentiment\n",
      "\n",
      "['cnk', 'huge', 'opportunity', 'cinemark']\n",
      "[[0.58974128]]\n",
      "Positive sentiment\n",
      "\n",
      "['fuck', 'mod']\n",
      "[[0.11981283]]\n",
      "Negative sentiment\n",
      "\n",
      "['canopy', 'growth', 'earnings', 'substantial', 'revenue', 'increase', 'crushed', 'eps', 'reported', 'positive', 'earnings', 'per', 'share', 'v', 'expected', 'loss']\n",
      "[[0.82107706]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'hims']\n",
      "[[0.99833943]]\n",
      "Positive sentiment\n",
      "\n",
      "['astr', 'gain', 'porn', 'plus', 'good', 'dd']\n",
      "[[0.91648018]]\n",
      "Positive sentiment\n",
      "\n",
      "['thanks', 'qualcomm', 'vne', 'gain']\n",
      "[[0.91961151]]\n",
      "Positive sentiment\n",
      "\n",
      "['nucor', 'nue', 'brainer', 'play']\n",
      "[[0.58196698]]\n",
      "Positive sentiment\n",
      "\n",
      "['nucor', 'nue', 'brained', 'play']\n",
      "[[0.58196698]]\n",
      "Positive sentiment\n",
      "\n",
      "['honest', 'day', 'work', 'thanks', 'momma', 'su']\n",
      "[[0.66185503]]\n",
      "Positive sentiment\n",
      "\n",
      "['pltr', 'yolo']\n",
      "[[0.99937612]]\n",
      "Positive sentiment\n",
      "\n",
      "['yolo', 'spx', 'lfg']\n",
      "[[0.99840573]]\n",
      "Positive sentiment\n",
      "\n",
      "['edu', 'earnings', 'yolo']\n",
      "[[0.99880174]]\n",
      "Positive sentiment\n",
      "\n",
      "['baba', 'tx', 'yolo']\n",
      "[[0.99853732]]\n",
      "Positive sentiment\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply prediction to all titles\n",
    "y_hat = []\n",
    "for text in final_df['title']:\n",
    "    print(clean_stopword_lemma(text))\n",
    "    y_pred = predict_logistic_regression(text, freqs, theta)\n",
    "    print(y_pred)\n",
    "    if y_pred > 0.5:\n",
    "        y_hat.append(1)\n",
    "        print('Positive sentiment\\n')\n",
    "    else:\n",
    "        y_hat.append(0)\n",
    "        print('Negative sentiment\\n')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Naive Bayes Gaussian Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.518</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos class\n",
       "0  0.518  0.482  0.000     0\n",
       "1  0.000  0.427  0.573     1\n",
       "2  0.000  0.444  0.556     1\n",
       "3  0.000  0.417  0.583     1\n",
       "4  0.000  0.000  1.000     1"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using prof's naive bayes gaussian as reference\n",
    "# Create a df for naive bayes\n",
    "# I used neg, neu, and pos to determine whether its sentiment value\n",
    "# In combine_df, I had already removed neutral classes\n",
    "naive_df = combine_df[['neg', 'neu', 'pos', 'class']].copy()\n",
    "naive_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2745274527452745, 0.7254725472547254]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the prior belief\n",
    "def calculate_prior(df, Y):\n",
    "    classes = sorted(list(df[Y].unique()))\n",
    "    prior = []\n",
    "    for i in classes:\n",
    "        prior.append(len(df[df[Y] == i])/len(df))\n",
    "    return prior\n",
    "\n",
    "\n",
    "# Test\n",
    "calculate_prior(naive_df, Y=\"class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the likelihood\n",
    "# Calculate P(X=x|Y=y) using Gaussian dist.\n",
    "def calculate_likelihood_gaussian(df, feat_name, feat_val, Y, label):\n",
    "    feat = list(df.columns)\n",
    "    df = df[df[Y] == label]\n",
    "    mean, std = df[feat_name].mean(), df[feat_name].std()\n",
    "    p_x_given_y = (1 / (np.sqrt(2 * np.pi) * std)) * \\\n",
    "        np.exp(-((feat_val-mean)**2 / (2 * std**2)))\n",
    "    return p_x_given_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate P(X=x1|Y=y)P(X=x2|Y=y)...P(X=xn|Y=y) * P(Y=y) for all y and find the maximum\n",
    "def naive_bayes_gaussian(df, X, Y):\n",
    "    # get feature names\n",
    "    features = list(df.columns)[:-1]\n",
    "\n",
    "    # calculate prior\n",
    "    prior = calculate_prior(df, Y)\n",
    "\n",
    "    Y_pred = []\n",
    "    # loop over every data sample\n",
    "    for x in X:\n",
    "        # calculate likelihood\n",
    "        labels = sorted(list(df[Y].unique()))\n",
    "        likelihood = [1]*len(labels)\n",
    "        for j in range(len(labels)):\n",
    "            for i in range(len(features)):\n",
    "                likelihood[j] *= calculate_likelihood_gaussian(\n",
    "                    df, features[i], x[i], Y, labels[j])\n",
    "\n",
    "        # calculate posterior probability (numerator only)\n",
    "        post_prob = [1]*len(labels)\n",
    "        for j in range(len(labels)):\n",
    "            post_prob[j] = likelihood[j] * prior[j]\n",
    "\n",
    "        Y_pred.append(np.argmax(post_prob))\n",
    "\n",
    "    return np.array(Y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Gaussian Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0\n",
      " 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0\n",
      " 1]\n",
      "[1 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0\n",
      " 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0\n",
      " 1]\n",
      "[[166, 0], [1, 56]]\n",
      "Naive Bayes Gaussian model's accuracy = 0.9955\n"
     ]
    }
   ],
   "source": [
    "# Apply to naive bayes gaussian\n",
    "train, test = train_test_split(naive_df, test_size=.2, random_state=41)\n",
    "\n",
    "X_test = test.iloc[:, :-1].values\n",
    "Y_test = test.iloc[:, -1].values\n",
    "Y_pred = naive_bayes_gaussian(train, X=X_test, Y=\"class\")\n",
    "\n",
    "print(Y_test)\n",
    "print(Y_pred)\n",
    "\n",
    "# Gets an error saying that we have a regression problem\n",
    "# Not a classification problem\n",
    "# So we cannot use confusion matrix, or f1_score\n",
    "'''\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred))\n",
    "'''\n",
    "\n",
    "# Decided to generate the confusion matrix by hand\n",
    "# I found TP, TN, FP, FN by hand so some errors my occur\n",
    "# Reference: https://towardsdatascience.com/taking-the-confusion-out-of-confusion-matrices-c1ce054b3d3e\n",
    "TP = 166\n",
    "FP = 0\n",
    "TN = 56\n",
    "FN = 1\n",
    "\n",
    "# Confusion matrix by hand\n",
    "cm = [[TP, FP],[FN, TN]]\n",
    "print(cm)\n",
    "\n",
    "# accuracy is too high to be called \"good\"\n",
    "# I suspect that there is overfitting\n",
    "accuracy = (TP+TN)/(TP+FP+TN+FN)\n",
    "print(f\"Naive Bayes Gaussian model's accuracy = {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistics Regression</td>\n",
       "      <td>0.919283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes Gaussian</td>\n",
       "      <td>0.995516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy\n",
       "0  Logistics Regression  0.919283\n",
       "1  Naive Bayes Gaussian  0.995516"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather results\n",
    "model_results = pd.DataFrame([['Naive Bayes Gaussian', accuracy]],\n",
    "               columns = ['Model', 'Accuracy'])\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Naive Bayes Catergorical Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_neg</th>\n",
       "      <th>cat_neu</th>\n",
       "      <th>cat_pos</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat_neg cat_neu cat_pos class\n",
       "0       1       2       0     0\n",
       "1       0       2       1     1\n",
       "2       0       2       1     1\n",
       "3       0       2       1     1\n",
       "4       0       0       2     1\n",
       "5       0       2       1     1\n",
       "6       0       1       2     1\n",
       "7       0       1       1     1\n",
       "8       1       2       0     0\n",
       "9       0       2       1     1"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert continuous features to Categorical features\n",
    "naive_df[\"cat_neg\"] = pd.cut(\n",
    "    naive_df[\"neg\"].values, bins=3, labels=[0, 1, 2])\n",
    "naive_df[\"cat_neu\"] = pd.cut(\n",
    "    naive_df[\"neu\"].values, bins=3, labels=[0, 1, 2])\n",
    "naive_df[\"cat_pos\"] = pd.cut(\n",
    "    naive_df[\"pos\"].values, bins=3, labels=[0, 1, 2])\n",
    "\n",
    "naive_df = naive_df.drop(columns=[\"neg\", \"neu\", \"pos\"])\n",
    "naive_df = naive_df[[\"cat_neg\",\t\"cat_neu\",\t\"cat_pos\", \"class\"]]\n",
    "naive_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate P(X=x|Y=y) categorically\n",
    "def calculate_likelihood_categorical(df, feat_name, feat_val, Y, label):\n",
    "    feat = list(df.columns)\n",
    "    df = df[df[Y] == label]\n",
    "    p_x_given_y = len(df[df[feat_name] == feat_val]) / len(df)\n",
    "    return p_x_given_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate P(X=x1|Y=y)P(X=x2|Y=y)...P(X=xn|Y=y) * P(Y=y) for all y and find the maximum\n",
    "def naive_bayes_categorical(df, X, Y):\n",
    "    # get feature names\n",
    "    features = list(df.columns)[:-1]\n",
    "\n",
    "    # calculate prior\n",
    "    prior = calculate_prior(df, Y)\n",
    "\n",
    "    Y_pred = []\n",
    "    # loop over every data sample\n",
    "    for x in X:\n",
    "        # calculate likelihood\n",
    "        labels = sorted(list(df[Y].unique()))\n",
    "        likelihood = [1]*len(labels)\n",
    "        for j in range(len(labels)):\n",
    "            for i in range(len(features)):\n",
    "                likelihood[j] *= calculate_likelihood_categorical(\n",
    "                    df, features[i], x[i], Y, labels[j])\n",
    "\n",
    "        # calculate posterior probability (numerator only)\n",
    "        post_prob = [1]*len(labels)\n",
    "        for j in range(len(labels)):\n",
    "            post_prob[j] = likelihood[j] * prior[j]\n",
    "\n",
    "        Y_pred.append(np.argmax(post_prob))\n",
    "\n",
    "    return np.array(Y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Categorical Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0\n",
      " 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0\n",
      " 1]\n",
      "[1 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0\n",
      " 0 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 1 0\n",
      " 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0\n",
      " 1]\n",
      "[[167, 0], [0, 56]]\n",
      "Naive Bayes Categorical model's accuracy = 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Apply naive bayes categorical method\n",
    "train, test = train_test_split(naive_df, test_size=.2, random_state=41)\n",
    "\n",
    "X_test = test.iloc[:, :-1].values\n",
    "Y_test = test.iloc[:, -1].values\n",
    "Y_pred = naive_bayes_categorical(train, X=X_test, Y=\"class\")\n",
    "\n",
    "print(Y_test)\n",
    "print(Y_pred)\n",
    "\n",
    "# Similar problem like in gaussian method\n",
    "# Gets an error saying that we have a regression problem\n",
    "# Not a classification problem\n",
    "# So we cannot use confusion matrix, or f1_score\n",
    "'''\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(f1_score(Y_test, Y_pred))\n",
    "'''\n",
    "\n",
    "# Decided to generate the confusion matrix by hand\n",
    "# I found TP, TN, FP, FN by hand so some errors my occur\n",
    "# Reference: https://towardsdatascience.com/taking-the-confusion-out-of-confusion-matrices-c1ce054b3d3e\n",
    "TP = 167\n",
    "FP = 0\n",
    "TN = 56\n",
    "FN = 0\n",
    "\n",
    "# Confusion matrix by hand\n",
    "cm = [[TP, FP],[FN, TN]]\n",
    "print(cm)\n",
    "\n",
    "# accuracy is too high to be called \"good\"\n",
    "# I suspect that there is overfitting\n",
    "accuracy = (TP+TN)/(TP+FP+TN+FN)\n",
    "print(f\"Naive Bayes Categorical model's accuracy = {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistics Regression</td>\n",
       "      <td>0.919283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes Gaussian</td>\n",
       "      <td>0.995516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes Categorical</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Accuracy\n",
       "0     Logistics Regression  0.919283\n",
       "1     Naive Bayes Gaussian  0.995516\n",
       "2  Naive Bayes Categorical  1.000000"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather results\n",
    "model_results = pd.DataFrame([['Naive Bayes Categorical', accuracy]],\n",
    "               columns = ['Model', 'Accuracy'])\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.weights = np.random.randn(\n",
    "            input_size, output_size) / np.sqrt(input_size + output_size)\n",
    "        self.bias = np.random.randn(\n",
    "            1, output_size) / np.sqrt(input_size + output_size)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return np.dot(input, self.weights) + self.bias\n",
    "\n",
    "    def backward(self, output_error, learning_rate):\n",
    "        input_error = np.dot(output_error, self.weights.T)\n",
    "        weights_error = np.dot(self.input.T, output_error)\n",
    "        # bias_error = output_error\n",
    "\n",
    "        self.weights -= learning_rate * weights_error\n",
    "        self.bias -= learning_rate * output_error\n",
    "        return input_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationLayer:\n",
    "    def __init__(self, activation, activation_prime):\n",
    "        self.activation = activation\n",
    "        self.activation_prime = activation_prime\n",
    "\n",
    "    # returns the activated input\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return self.activation(input)\n",
    "\n",
    "    # Returns input_error=dE/dX for a given output_error=dE/dY.\n",
    "    # learning_rate is not used because there is no \"learnable\" parameters.\n",
    "    def backward(self, output_error, learning_rate):\n",
    "        return output_error * self.activation_prime(self.input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenLayer:\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def forward(self, input):\n",
    "        return np.reshape(input, (1, -1))\n",
    "\n",
    "    def backward(self, output_error, learning_rate):\n",
    "        return np.reshape(output_error, self.input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLayer:\n",
    "    def __init__(self, input_size):\n",
    "        self.input_size = input_size\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        tmp = np.exp(input)\n",
    "        self.output = tmp / np.sum(tmp)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output_error, learning_rate):\n",
    "        input_error = np.zeros(output_error.shape)\n",
    "        out = np.tile(self.output.T, self.input_size)\n",
    "        return self.output * np.dot(output_error, np.identity(self.input_size) - out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return np.exp(-x) / (1 + np.exp(-x))**2\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "def tanh_prime(x):\n",
    "    return 1 - np.tanh(x)**2\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "\n",
    "def relu_prime(x):\n",
    "    return np.array(x >= 0).astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.power(y_true - y_pred, 2))\n",
    "\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return 2 * (y_pred - y_true) / y_pred.size\n",
    "\n",
    "\n",
    "def sse(y_true, y_pred):\n",
    "    return 0.5 * np.sum(np.power(y_true - y_pred, 2))\n",
    "\n",
    "\n",
    "def sse_prime(y_true, y_pred):\n",
    "    return y_pred - y_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.518</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     neg    neu    pos class\n",
       "0  0.518  0.482  0.000     0\n",
       "1  0.000  0.427  0.573     1\n",
       "2  0.000  0.444  0.556     1\n",
       "3  0.000  0.417  0.583     1\n",
       "4  0.000  0.000  1.000     1"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_df = combine_df[['neg', 'neu', 'pos', 'class']].copy()\n",
    "nn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: read everything but \"class\"\n",
    "# Y: read only \"class\", 0s and 1s\n",
    "X = nn_df.iloc[:, :-1].values\n",
    "y = nn_df['class'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set training and testing sets\n",
    "X_train = X_train.astype('float32')\n",
    "X_train /= 255\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "X_train = X_train[0:1000]\n",
    "y_train = y_train[0:1000]\n",
    "\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255\n",
    "y_test = np_utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((888, 3), (888, 2), (223, 3), (223, 2))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/40, error=0.208431\n",
      "2/40, error=0.207206\n",
      "3/40, error=0.206959\n",
      "4/40, error=0.206822\n",
      "5/40, error=0.206745\n",
      "6/40, error=0.206704\n",
      "7/40, error=0.206681\n",
      "8/40, error=0.206669\n",
      "9/40, error=0.206662\n",
      "10/40, error=0.206659\n",
      "11/40, error=0.206657\n",
      "12/40, error=0.206656\n",
      "13/40, error=0.206655\n",
      "14/40, error=0.206655\n",
      "15/40, error=0.206655\n",
      "16/40, error=0.206655\n",
      "17/40, error=0.206655\n",
      "18/40, error=0.206655\n",
      "19/40, error=0.206655\n",
      "20/40, error=0.206655\n",
      "21/40, error=0.206655\n",
      "22/40, error=0.206654\n",
      "23/40, error=0.206654\n",
      "24/40, error=0.206654\n",
      "25/40, error=0.206654\n",
      "26/40, error=0.206654\n",
      "27/40, error=0.206654\n",
      "28/40, error=0.206654\n",
      "29/40, error=0.206654\n",
      "30/40, error=0.206654\n",
      "31/40, error=0.206654\n",
      "32/40, error=0.206654\n",
      "33/40, error=0.206654\n",
      "34/40, error=0.206654\n",
      "35/40, error=0.206654\n",
      "36/40, error=0.206654\n",
      "37/40, error=0.206654\n",
      "38/40, error=0.206654\n",
      "39/40, error=0.206654\n",
      "40/40, error=0.206654\n"
     ]
    }
   ],
   "source": [
    "# unlike the Medium article, I am not encapsulating this process in a separate class\n",
    "# I think it is nice just like this\n",
    "network = [\n",
    "    FlattenLayer(input_shape=(3)),\n",
    "    FCLayer(3 * 1, 3),\n",
    "    ActivationLayer(relu, relu_prime),\n",
    "    FCLayer(3, 2),\n",
    "    SoftmaxLayer(2)\n",
    "]\n",
    "\n",
    "epochs = 40\n",
    "learning_rate = 0.1\n",
    "\n",
    "# training\n",
    "for epoch in range(epochs):\n",
    "    error = 0\n",
    "    for x, y_true in zip(X_train, y_train):\n",
    "        # forward\n",
    "        output = x\n",
    "        for layer in network:\n",
    "            output = layer.forward(output)\n",
    "\n",
    "        # error (display purpose only)\n",
    "        error += mse(y_true, output)\n",
    "\n",
    "        # backward\n",
    "        output_error = mse_prime(y_true, output)\n",
    "        for layer in reversed(network):\n",
    "            output_error = layer.backward(output_error, learning_rate)\n",
    "\n",
    "    error /= len(X_train)\n",
    "    print('%d/%d, error=%f' % (epoch + 1, epochs, error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio: 0.77\n",
      "mse: 0.1768\n"
     ]
    }
   ],
   "source": [
    "def predict_neural_network(network, input):\n",
    "    output = input\n",
    "    for layer in network:\n",
    "        output = layer.forward(output)\n",
    "    return output\n",
    "\n",
    "\n",
    "ratio = sum([np.argmax(y) == np.argmax(predict_neural_network(network, x))\n",
    "             for x, y in zip(X_test, y_test)]) / len(X_test)\n",
    "error = sum([mse(y, predict_neural_network(network, x))\n",
    "             for x, y in zip(X_test, y_test)]) / len(X_test)\n",
    "print('ratio: %.2f' % ratio)\n",
    "print('mse: %.4f' % error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 0\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n",
      "pred: 1, prob: 0.75, true: 1\n"
     ]
    }
   ],
   "source": [
    "for test, true in zip(X_test, y_test):\n",
    "    image = np.reshape(test, (3, 1))\n",
    "    pred = predict_neural_network(network, test)[0]\n",
    "    idx = np.argmax(pred)\n",
    "    idx_true = np.argmax(true)\n",
    "    print('pred: %s, prob: %.2f, true: %d' % (idx, pred[idx], idx_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[172, 51], [0, 0]]\n",
      "Naive Bayes Categorical model's accuracy = 0.7713\n"
     ]
    }
   ],
   "source": [
    "# Find accuracy\n",
    "# Decided to generate the confusion matrix by hand\n",
    "# I found TP, TN, FP, FN by hand so some errors my occur\n",
    "# Reference: https://towardsdatascience.com/taking-the-confusion-out-of-confusion-matrices-c1ce054b3d3e\n",
    "TP = 172\n",
    "FP = 51\n",
    "TN = 0\n",
    "FN = 0\n",
    "\n",
    "# Confusion matrix by hand\n",
    "cm = [[TP, FP],[FN, TN]]\n",
    "print(cm)\n",
    "\n",
    "# accuracy is too high to be called \"good\"\n",
    "# I suspect that there is overfitting\n",
    "accuracy = (TP+TN)/(TP+FP+TN+FN)\n",
    "print(f\"Naive Bayes Categorical model's accuracy = {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistics Regression</td>\n",
       "      <td>0.919283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes Gaussian</td>\n",
       "      <td>0.995516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes Categorical</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>0.771300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Accuracy\n",
       "0     Logistics Regression  0.919283\n",
       "1     Naive Bayes Gaussian  0.995516\n",
       "2  Naive Bayes Categorical  1.000000\n",
       "3           Neural Network  0.771300"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gather results\n",
    "model_results = pd.DataFrame([['Neural Network', accuracy]],\n",
    "               columns = ['Model', 'Accuracy'])\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "533e98f5e8b84dc248a9ac5019554f88a2a445e6fff339af924c1909d9276bb8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
